# Лекция 2. Линейная регрессия, Ridge и Lasso

**Общее про регуляризацию:**

Регуляризация необходима для того, чтобы снизить риски переобучения. Когда модель переобучена, некоторые ее веса огромные по модулю, таким образом модель очень "извилистая". А регуляризация применяет штраф на эти веса (или же излишнюю сложность) и модель становится более гладкой.

  

![400](https://deepmachinelearning.ru/assets/images/under-overfitting-9c300b48dd2371dbcd5bd2fda7a930e9.png)

  

>[!question]- 3. Записать функционал Ridge-регрессии (L2-регуляризации) и объяснить, как L2-штраф влияет на значения коэффициентов и устойчивость модели.
>
> **Формула L2**
>
> $$J_{\text{ridge}}(\mathbf w,b)=\operatorname{MSE}(\mathbf w,b) + \lambda\,\lVert\mathbf w\rVert_2^2 = \operatorname{MSE}(\mathbf w,b) + \lambda\,\sum_{i=0}^{d} w_{i}^2$$
>
> Задача: минимизация $J_{\text{ridge}}$
>
>- Штраф $\lVert\mathbf w\rVert_2^2$ - сумма квадратов весов
> - $\lambda$ > 0 - коэффициент регуляризации. Регулирует на сколько сильно мы штрафуем веса.
> 	- Слишком большая лямбда - слишком маленькие веса (недообучение).
> 	- Слишком маленькая лямбда - тогда она плохо регуляризирует, большие веса остаются (переобучение).
> 	
> **Эффект от штрафов:**
> - Штраф на крупные веса, сглаживание, коэффициенты "сжимаются" к нулю
> - Не обнуляет коэффициенты
> - Уменьшает дисперсию модели (оценок коэффициентов)
> - Устойчивость к шуму и мультиколлинеарности
> - Уменьшает переобучение
> - Делит веса между коррелирующими признаками
> - См. геометрическую интерпретацию ниже.
>
> Мультиколлинеарность - это когда две переменные сильно коррелируют (тесно связаны) друг с другом

  >[!question]-  4. Записать функционал Lasso-регрессии (L1-регуляризации) и объяснить, почему L1-штраф часто приводит к появлению нулевых коэффициентов (разреженности модели).
>
> **Формула L1**
> $$J_{\text{lasso}}(\mathbf w,b)=\operatorname{MSE}(\mathbf w,b) + \lambda\,\lVert\mathbf w\rVert_1 = \operatorname{MSE} + \lambda\sum_i |w_i|.$$
> 
> Задача: минимизировать $J_{\text{lasso}}$
> - Штраф $\,\lVert\mathbf w\rVert_1$ - сумма абсолютной величины весов
> - Зависимость от $\lambda$ такая же, как в L2
> 
> Но Lasso может занулять некоторые признаки что приводит к обнулению некоторых признаков (разреженное решение). См. геометрическую интерпретацию ниже.
>
> **Эффект от штрафов**
> - то же самое, что и в L2, кроме:
> 	- обнуляет коэффициенты
>	- Часто выбирает один признак среди коррелирующих

>[!question]-  5. Сравнить Ridge и Lasso-регрессии: в каких ситуациях предпочтителен каждый из методов, что такое Elastic Net и как он сочетает L1 и L2-штрафы.
> 
> **Геометрическая интерпретация**
>
> ![400](https://i.imgur.com/MXWq02S.png)
> - Синее - наши веса
> - Красное - MSE
> - Черная точка - решение
> 
> 1. Из-за модулей у нас в L1 веса в виде ромбиков , а в L2 в виде окружности.
> 2. В L1 из-за углов ромба решение часто попадает в вершину, и тогда некоторые веса становятся нулем.
> 3. В L2 все веса умеренные по длине.
>
> **Ridge**:
>
> - много слабых признаков
> - важно стабилизировать веса
>
> **Lasso:**
>
> - мало важных признаков
> - интерпретируемость
>
> **Elastic Net:**
> $$\operatorname{MSE}(\mathbf w,b) + \lambda_1\lVert w\rVert_1 + \lambda_2\lVert w\rVert_2^2$$
> - Комбинация L1 и L2
> - $\lambda_1 = 0$ - применяем только Ridge,
> - $\lambda_2 = 0$ - применяем только Lasso
> 
> Используя Elastic Net, мы и убираем ненужные признаки, и уменьшаем переобучение. Разреженность + устойчивость. Используется когда много признаков и корреляций.

  

>[!question]- 6. Объяснить, зачем перед применением регуляризованных моделей стандартизуют признаки. Как на практике подбирают параметр регуляризации ?
>
> **Стандартизация**
> Стандартизируя признаки, мы делаем их "безразмерными". Иными словами, регуляризованные модели чувствительны к масштабу, что может привести к неверному штрафу весов, и, соответсвенно, коэффициентам.
> 
> **Подбор параметра $\lambda$**
>
> 1. Кросс-валидация или train/validation/test
> 2. Стандартизация
> 3. Проверка пере/недообучения по кривым валидации
> 4. Попробовать и Ridge, и Lasso, сравнить их по валидации.
> 5. Выбираем $\lambda$ с минимальной ошибкой
> 6. Кривая валидации - для каждого $\lambda$ обучаем модель и считаем ее ошибку на train и validation, строим график.
>
> Еще можно использовать поиск по сетке (GridSearch)
>
> **Примеры скейлеров**
>
> StandardScaler() - удаляет среднее значение и масштабирует данные до единичной дисперсии
> MinMaxScaler() - масштабирует все признаки данных в диапазоне [0, 1]

# Лекция 3. Логистическая регрессия
>[!question]- 3. Записать и\_ли объяснить выражение для вероятности наблюдения у є {0,1} при фиксированном х и параметрах модели. Записать и\_ли объяснить правдоподобие выборки как произведение по объектам¹.
>
> **Распределение Бернулли**
> У эксперимента есть два исхода - успех или неуспех. Мы хотим получить вероятность успеха ($y=1$)
> $$\hat p=\Pr(y=1\mid\mathbf x)$$
> **Сигмоида**
> Сигмоида задает параметр распредления Бернулли, и в отличие от линейной регрессии, на выход выдается вероятность $$\hat p = \sigma(z)\in[0,1]$$
> $$\sigma(z) = \frac{1}{1 + e^{-z}}\, , \qquad $$
> $$ z = \mathbf w^\top \mathbf x + b = \sum_{j=1}^{d} w_j x_j + b \in (-\infty, +\infty) $$
> - z - линейный отклик; 
> - x - вектор признаков; 
> - w - вектор весов; 
> - b - свободный член
> Подробнее про это есть в билете 2.1
>
> Сигмоида превращает неограниченный $z$ в вероятность, делая плавный переход между 2-мя классами. Чем дальше от границы решений ($z=0$) , тем выше уверенность.
> Крутая картинка сигмоиды:
> ![240](https://www.dmitrymakarov.ru/wp-content/uploads/2021/10/sigmoid-1024x523.png)
> По оси абсцисс - $z$, по оси ординат - $\sigma(z)$
> 
> **Выражения вероятности**
> - Для одного примера (стандартная форма распределения Бернулли):
> $$ p(y\mid \mathbf x) = \sigma(z)^y\, \bigl(1-\sigma(z)\bigr)^{(1-y)}, \quad y\in\{0,1\}. $$
> - y - правильный ответ
> - $\sigma(z)\,$- вероятность класса 1
> - $\bigl(1-\sigma(z)\bigr)$ - вероятность класса 0
> - Степени $y$ и $(1-y)$ "включают" или"выключают" множитель.
>
> Эта форма универсальна для обоих классов и используется при максимизации правдоподобия.
> После перемножения мы получаем вероятность класса.
> 
> - Для всей выборки (независимость примеров):
>
> $$ \mathcal L(\mathbf w,b) = \prod_{i=1}^n \sigma(z_i)^{y_i}\, \bigl(1-\sigma(z_i)\bigr)^{(1-y_i)}, $$
> $$ \quad z_i=\mathbf w^\top\mathbf x_i+b$$
> Перемножаем результат для одно объекта со всеми остальными, чтобы получить вероятность(правдоподобие) для всей выборки. Это значение мы хотим максимизировать.

>[!question]- 4. Вывести, привести и\_ли объяснить выражение для функции потерь логистической регрессии (log loss)¹.
> **Вывод log loss** (кросс-энтропийная потеря)
> 
> Log loss выводится из правдоподобия.
>
> 1) Логарифмируем произведение (сумма логов), т.к.:
>
> 	- после перемножения чисел от 0 до 1 итоговое произведение будет очень маленьким (при большой выборке)
> 	- работать с суммами гораздо удобнее чем с произведением.
> 	- суммы лучше дифференцируются, эффективный градиентный спуск 
> 	- $y_i$, которое стояло в степени, выносится по свойству логарифмов.
> 	$$
> 	\begin{equation*}
> 	\log \mathcal L = \sum_{i=1}^n \Bigl[ y_i\,\log\sigma(z_i) + (1-y_i)\,\log\bigl(1-\sigma(z_i)\bigr) \Bigr].
> 	\end{equation*}$$
> 2) Меняем знак, добавляем минус (минимизация вместо максимизации)
> -  Добавляем также усреднение по количеству объектов.
> 	$$ J(\mathbf w,b) = -\,\frac{1}{n}\sum_{i=1}^n \Bigl[ y_i\,\log\sigma(z_i) + (1-y_i)\,\log\bigl(1-\sigma(z_i)\bigr) \Bigr].$$
> Log loss мы хотим минимизировать, а правдоподобие максимизировать.

>[!question]- 5. Пояснить, как и зачем добавляются L1- и L2-регуляризации в логистическую регрессию. Как регуляризация влияет на переобучение и интерпретируемость модели?
>
> Всё то же самое, как и с LinReg
> Подробнее можно почитать в лекции 2 вопросы 3-6
> **Регуляризациия нужна чтобы:**
> - избежать переобучения
> - стабилизировать веса
> $$J_{\text{ridge}} = J + \lambda\,\lVert\mathbf w\rVert_2^2, \qquad$$
> $$J_{\text{lasso}} = J + \lambda\,\lVert\mathbf w\rVert_1$$
>
> **Интерпретируемость**
> - L1 повышает интерпретируемость, тк уменьшает количество признаков
> - L2 учитывает все признаки, сложнее понять какие действительно важны

# Лекция 4. Решающие деревья и ансамбли (бэггинг, случайные леса, стэкинг)
**Общее про решающие деревья**

***Основная идея***
Построить двоичное дерево условий, по которым будет производится предсказание класса объекта (классификация) или числового признака объекта (регрессия), где во внутреннем узле (все узлы, кроме нижних) дерева будет находится условие, а в листе (самый нижний узел) - предсказание класса объекта или числового признака объекта.

***Обучение*** 
Для выборки ищем такие признак и порог (с чем сравнивается признак для разбиения на подвыборку), для которых при разбиении на две подвыборки разные классы будут максимально распределены по подвыборкам (можно замерить индексом Джини, или посчитав энтропию). Выбранное условие ставится в узел, затем то же самое проводится с листами получившегося узла.

Когда достигаем максимальной глубины, в лист ставим предсказание, может быть классом (классификация) или числом (регрессия) - мода для подвыборки.

>[!question]- 1. Описать структуру решающего дерева: что такое внутренний узел, лист, ребра, глубина дерева. Чем дерево классификации отличается от дерева регрессии по типу предсказания в листе?

  

Внутренний узел - узел с условием, по которому делается предсказание

Лист - предсказание дерева, может быть классом (классификация) или числом (регрессия)

Ребро - варианты ответа на условие, заданное в листе (true/false)

Глубина дерева - максимальное количество вопросов от корня до листа.

У дерева классификации в листе находится класс, у дерева регрессии - число.

  

2. Объяснить пошагово, как решающее дерево делает предсказание для одного объекта.

  

Начинаем с корня дерева, в котором стоит условие. Если для класса условие выполняется, идем по ребру “да”, иначе - по ребру “нет”. После этого мы можем попасть либо в внутренний узел с условием, либо в лист с предсказанием. Если внутренний узел - повторяем то же, что и с корнем. Если лист с предсказанием - выдаем предсказание.

p.s. думаю, для наглядности можете во время зачета нарисовать какое-то дерево и все наглядно объяснить.

# Лекция 5. Бустинг и градиентный бустинг над деревьями
>[!question]- 1. Сформулировать общую идею бустинга. Чем бустинг принципиально отличается от бэггинга и стэкинга?
>
> **Общая идея**
> 
> Последовательное добавление слабых моделей, каждая из которых исправляет ошибки предыдущей, i.e. предсказывает ошибку предыдущей.
>
> ***Отличие от бэггинга и стэкинга***
>   
> При бэггинге обучется несколько моделей, и финальное предсказание формируется "голосованием" (берется мода или среднее от всех предсказаний)
> При стэкинге на предсказаниях нескольких моделей обучается еще одна модель, которая сможет лучше комбинировать их ответы, чем просто мода или среднее.
> При бустинге же модели работают как бы не параллельно, а последовательно. Каждая последующая модель, кроме первой, старается предсказать не таргет переменную, как в бэггинге или стэкинге, а ошибку предыдущей модели.
> Бэггинг и стэкинг менее чувствительны к отдельным выбросам. Бустинг чувствителен к шуму (важна регуляризация).

>[!question]- 2. Записать и_ли объяснить объяснить общее обновление модели в градиентном бустинге [1]
> $$ F_{M}(x) = F_{M-1}(x) + v*h_{m}(x) $$
> 
> Где 
> - $F_{0}(x)$ - изначальная модель, которая грубо предсказывает ошибку
> - $h_{M}(x)$ - модель, которая предсказывает ошибки $F_{M-1}(x)  
> - $v \in (0; 1]$ - скорость обучения (i.e. как сильно модель каждой итерации влияет на конечную модель. Чем меньше  скорость обучения, тем больше нужно обучить моделей, но тем более точно можно скорректировать финальную модель)
> 
> Оно же:
> 
> $$ F(x) = F_{0}(x) + \sum_{i=1}^{h} h_{i}(x) * v^i $$

>[!question]- 3. Пояснить точку зрения градиентного спуска в пространстве функций: как задается функционал ошибки L(F) и какую роль играют псевдо-остатки (антиградиенты) на обучающих объектах.
>
> **Пространство функций**
>
> Пространство функций - это множество слабых функций h, которые мы перебираем для нахождения лучшей финальной функции F
>
> **Как задается функционал ошибка L(F)**
> 
> $$ L(F) = \sum_{i=1}^{n}l(y_{i}, F(x_{i})) $$
> 
> Где F - искомая функция, а l - выбранная функция потерь.
> 
>  **Псевдо-остатки**
>  
>  На каждом шаге нам нужна модель h, которая будет предсказывать ошибку прошлой модели F. 
> 
>  $$ g_{im} = \frac{\partial l(y_{i}, F_{m-1}(x_{i}))}{\partial F_{m-1}(x_{i})} $$
>  
>  $$ h_{m} \approx -g_{im} $$
>  
>  I.e. псевдо-остатки (производная Фреше в обобщенном метрическом пространстве) пропорциональны предсказаниям модели h.
>  
>  Градиентный бустинг называется так, т.к. формула сильно похожа на формулу градиентного спуска
>  
>  $$ x = x_{0} - \sum_{i=1}^{n} v_{i} g_{'}(x_{i}) $$

> [!question]- 4. Записать и_ли объяснить шаг алгоритма градиентного бустинга над деревьями: вычисление псевдо-остатков, обучение регрессионного дерева по этим значениям, поиск оптимальных сдвигов по листам и обновление ансамбля [1]
> 
> 1. Вычисление псевдо-остатков $$ r_{im} = \frac{\partial l(y_{i}, F_{m-1}(x_{i}))}{\partial F_{m-1}(x_{i})} $$
> 2. Обучение регрессионного дерева $h_{m}(x)$ по парам ($x_{i}$, $r_{im}$)
> 3. Нахождение оптимального сдвига (константы) по листам: для каждого листа $R_{jm}$ $$ γ_{jm} = arg\min_{γ} \sum_{x_{i} \in R_{jm}} l(y_{i}, F_{m-1}(x_{i}) + γ) $$
> 4. Обновление модели $$ F_{m}(x) = F_{m-1}(x) + v * \sum_{j} γ_{jm} 1\{x \in R_{jm} \} $$

>[!question]- 5. Перечислить основные способы регуляризации в градиентном бустинге: малая скорость обучения v, ограничение глубины деревьев, минимальный размер листа, субсемплинг объектов, субсемплинг признаков, ранняя остановка по валидационной выборке.
>
> 1. Скорость обучения (shrinkage)  $v \in (0; 1]$. Чем меньше, тем устойчивее, но нужно больше деревьев.
> 2. Глубина дерева / число листьев: неглубокие деревья (3-8 уровней) приводят к слабым базовым моделям.
> 3. Субсемплинг объектов: обучение $h_{m}$ на случайной доле данных (обычно от 0.5 до 0.9)
> 4. Субсемплинг признаков: случайный поднабор признаков на сплите/уровне/дереве.
> 5. Минимальный размер листа, L2-штраф на веса листок, макс. число узлов.
> 6. Ранняя остановка по валидации: мониторинг метрики и прекращение роста M (перетекает в некст вопрос)

>[!question]- 6. Объяснить, как по поведению метрик на обучающей и валидационной выборках диагностировать переобучение бустинговой модели и как выбирать оптимальное число итераций.
>
> **Переобучение**
> 
> При подборе гиперпараметров нужно стремиться к уменьшению метрики на валидации и сохранению метрики на обучающей выборке. Если материка на обучающей выборке уменьшается, а на валидационной - нет, то это признак переобучения.
> 
> **Число итераций**
> 
> Подбирается так же, как и любой гиперпараметр, - по метрике валидационной выборке

# Лекция 6. Кластеризация, SVD и PCA
>[!question]- 1.  Дать определение обучению без учителя. Какие задачи обычно относят к обучению без учителя? Приведите примеры.
> **Определение**
> Обучение без учителя - это метод машинного обучения, при котором алгоритм работает с неразмеченными данными (отсутствие таргет-переменной, $y$) с целью обнаружить, как организованы данные.
> 
> **Примеры**
> Примерами являются: понижение размерности (матриц из данных) и кластеризация (разбиение данных на кластеры)
> 
> Примеры в реальной жизни: Геологическое обнаружение минералов, кластеризация генов, машинное зрение.

>[!question]- 2. Описать алгоритм K-Means. Записать и объяснить целевую функцию, которую алгоритм минимизирует
>
> **Алгоритм**
> 1. Выбирается K случайных (или по какому-то алгоритму) стартовых точек (центроидов)
> 2. Каждый элемент данных относится к тому же “кластеру”, что и ближайшая стартовая точка 
> 3. В каждом созданном кластере выбирается самый средний элемент - он будет выступать новым центроидом. Для новых центроидов снова выполняем пункт 2.
> 4. Повторяем пункты 2-3 до тех пор, пока кластеры практически не перестанут менятся
>
> **Минимизируемая функция**
>
> $$ J(C, \mu) = \sum_{k=1}^{K} \sum_{\mathbf{x}_i \in C_k} \|\mathbf{x}_i - \boldsymbol{\mu}_k \|^2 $$
> 
> Где
> - $x_{i}$ - точка
> - $\mu_{c(i)}$ - центр ее кластера
>
> То есть сумма от сумм расстояний каждого объекта до центроида  для каждого кластера. Все расстояния суммируем для кластера а потом и все кластеры суммируем

>[!question]- 3. Перечислить основные преимущества и недостатки K-Means. Как влияет масштабирование признаков и наличие выбросов на работу алгоритма?
>
>**Плюсы**
> 1. Быстрый (по сравнению с двумя другими известными алгоритмами) - асимптотическая сложность ниже ($n* k * d * t$ против кубических и квадратных), при этом операции вычисления оптимизированы под устройство процессора (векторные регистры)
> 2.  Масштабируемость на размеры - $O(n) = n*k*d*t$, где k - количество центроидов, d - длина векторов (features), t - количество итераций
> 2. Интерпретируемый - результатом становятся вполне объяснимые центры и близкие к ним данные
> 
> **Минусы**
> 1. Немасштабированные данные сильно ухудшают работоспособность, так как признаки с большим разбросом данных (большой масштаб) будут важнее более плотных
> 2. Выбросы также ломают модель, так как минимизируемая функция - квадрат расстояний, соответственно новый центроид будет сильно сдвинут

>[!question]- 4. Объяснить алгоритм DBSCAN. Каковы роли параметров e (epsilon) и min_samples? Чем отличаются ядровые, пограничные и шумовые точки?
> **Идея**
> 
> Кластерами будут зоны “высокой плотности” объектов, которые разделены границами - зонами “низкой плотности”.
> 
> **Алгоритм**
> 1. Выбираем произвольную точку.
> 2. Берём всех соседей в e (epsilon)-окрестности. 
> 3. Если количество соседей >= min_samples - в этой точке считаем новый кластер.
> 4. Если соседей меньше min_samples или точка не принадлежит уже созданному кластеру, то точка помечается как шум
> 5. Проходим также все оставшиеся точки.
>
> **Ядровые, пограничные и шумовые точки**
> 
> Ядровые - принадлежащие “внутренней” части обнаруженного кластера, не участвуют в обновлении новых точек.
> 
> Пограничные - точки на “границе” кластера - через них и epsilon и высчитывается принадлежность следующих точек.
> 
> Шумовые - помеченные как шум.

>[!question]- 5. Сравнить DBSCAN и K-Means по форме находящихся кластеров, устойчивости к выбросам, необходимости заранее задавать число кластеров и чувствительности к плотности данных?
>
> **Форма**
> 
> - K-Means - n-мерная сфера (окружность, при двух признаках), так как принадлежность определяется расстоянием до центра (центроида)
> - DBSCAN - произвольная форма, так как “расширение” кластера происходит засчёт граничных точек (ближайшие к границе)
>
> **Устойчивость к выбросам**
>
> - K-Means - отсутствует, так как выбросы сильно смещают центроиды (см. выше про квадрат расстояний)
> - DBSCAN - Высокая, так как способен различать шумы
>
> **Число кластеров**
> 
> - K-Means: заданное, K
> - DBSCAN: сам определяет их
>
>**Чувствительность к плотности данных**
>
> - K-Means: он игнорирует локальную плотность, разделяет зоны на равные по удалённости
> - DBSCAN: алгоритм основан на плотности, а потому равноплотные данные ухудшают работоспособность

>[!question]- 6. Описать идею агломеративной иерархической кластеризации: начальное состояние, правило слияния кластеров, возможные варианты связи (single, complete, average, Ward), роль дендрограммы.
>
> **Идея**
> 
> Не разделять данные на кластера сразу, а объединять близкие малые кластеры для получения больших. Принцип “снизу-вврех”.
>
> **Начальное состояние**
> 
> Важдый объект из выборки - кластер (всего их n)
>
> **Правило слияния** 
> 
> Выбираем у каждого кластера ближайший в соответствии с выбранным вариантом связи, объединяем их. Затем повторяем слияние новых кластеров с пересчитанным расстоянием
> 
> **Варианты связи**
> 
> - Single - расстояние между ближайшими точками кластеров
> - Complete - между самыми далёкими элементами
> - Average - между средними, “центрами” кластеров
> - Ward - сложный вид, на доп вопрос (кратко - минимизация внутрикластерной дисперсии)
>
> **Дендрограмма**
>
> Дендрограмма - древовидная диаграмма, которая визуализирует слияние малых кластеров (листьев) в конечные кластера. Уровень, на котором будет сделан “срез” диаграммы отсекает количество итоговых кластеров.

>[!question]- 7. Перечислить достоинства и недостатки иерархической кластеризации, в том числе с точки зрения вычислительной сложности и работы с большими выборками
>
> **Достоинства**
> 
> 1. Интерпретируемость. Наглядно показывает вложенность данных внутри кластера
> 2. Не требует задавать число кластеров, однако необходимо выбрать уровень детализации (уровня отсечения разных кластеров)
> 3.  Результат воспроизводимый, так как объединение кластеров не зависит от “случайности”
>
> **Недостатки**
>
> 1. Затрачивает много памяти (необходимо хранить расстояние между всеми парами значений)
> 2. Чувствителен к шуму. Объединение с близким шумовым объектом на раннем этапе ведёт к “связыванию” кластера с шумом
> 3. Необходимо выбирать метод связи - от этого зависит результат.
> 4. Не учитывает, что данные могут быть разбросаны произвольно, а не сферически-подобно
>
> ***Особенные недостатки***
> 
> 5. Как и с памятью, необходимо делать очень много вычислений $O(n) = n^3$ => долго
> 6. Из-за такой высокой асимптотической сложности, физически не способен кластеризировать выборки размером более 10^6 (или больше)

> [!question]- 8. Сформулировать основные цели снижения размерности и назвать несколько наиболее популярных алгоритмов.
> 
> **Цели**
> - Убрать мультиколениарные (говорящие об одном и том же, коррелирующие) признаки
> - Избавится от шумов (избавление от случайных значений
> - Решает проблему [проклятия размерности](https://en.wikipedia.org/wiki/Curse_of_dimensionality) (чем больше фич - тем труднее модели обучатся и легче переобучаться)
> - Ускорение работы моделей, обучаемых на данных: меньше фич -> меньше вычислений
> - Позволяет визуализировать данные. Например, в рамках кластеризации помогает преобразовать многомерное пространство в 2/3-мерное (чтобы наглядно увидеть распределение данных)
> - Сжимает данные -> меньше памяти
> - Выявление скрытых (латентных) признаков
>    
> **Популярные алгоритмы**
> (в подробностях - на доп вопрос, помните название только)
> 
> - PCA (Principal Component Analysis) - суть: преобразовать в новые оси (из многомерности в n-мерность), максимизируя при этом дисперсию (чтобы значение признака было говорящим)
> - SVD (Singular Value Decomposition) - матричная факторизация. Буквально поворот матрицы и умножение на саму себя для сжатие размерности (матрица размера $n*m$ становится матрицей размера $\min(n, m)^2$)
> - *t-SNE (t-distributed stochastic neighbour embedding) - один из нелинейных методов снижения размерности