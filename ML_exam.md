# Лекция 1.
>[!question]- 2. Сформулировать математическую постановку задачи обучения с учителем: выборка D = $\{(x_i, y_i)\}_{i=1}^{n}$, поиск модели $\mathcal{f}(x)$, минимизирующей ошибку на данных.
>
> С математической точки зрения обучение с учителем означает, что требуется определить такую функцию **$\mathcal{f}(x)$**, что функция потерь **$\mathcal{L}(f(x_i), y_i)$** будет стремиться к минимуму. То есть нужно подобрать параметры модели (коэффициенты при признаках) так, чтобы выходные данные минимально отличались от требуемых.
> **Важно:** Цель — не выучить данные наизусть, а обеспечить способность модели к **обобщению** на новые, ранее не встречавшиеся данные (проще говоря, избегать переобучения).

>[!question]- 3. Перечислить основные типы задач машинного обучения (обучения с учителем, обучения без учителя, обучения с подкреплением) и привести по одному примеру из каждого типа.
> 
> **Обучение с учителем**
> 
> **Суть:** Алгоритму на вход подается **размеченная выборка** — набор данных, где для каждого объекта известен правильный ответ (целевая переменная). Цель — научиться предсказывать этот ответ для новых объектов.
> - **Классификация**
> 	- **Цель:** предсказать категорию (спам/не спам и т.п.).
> 	- **Метрики:** Accuracy, Precision/Recall, F1.
> - **Регрессия**
> 	- **Цель:** предсказать число (например, цену).
> 	- **Метрики:** MAE, RMSE, R2.
>
>**Обучение без учителя**
>
> **Суть:** Алгоритму даются данные без готовых ответов или меток. Цель — найти скрытые структуры, закономерности или сгруппировать данные.
>
> - **Кластеризация**
> 	- **Пример:** группировка покупателей по поведению на сегменты.
> 	- **Алгоритмы:** k-means, иерархическая кластеризация, DBSCAN.
> - **Понижение размерности (PCA, SVD)**
> 	- **Пример:** сжатие данных для визуализации, сохраняя главные особенности.
> 
 > **Обучение с подкреплением**
>
>**Суть:** Алгоритм (агент) обучается, взаимодействуя со средой. Он совершает действия, получает за них вознаграждение (или штраф) и корректирует стратегию, чтобы максимизировать совокупную награду.
>
> -**Цель:** максимизировать суммарную награду.
>
> - **Примеры:** игра в шахматы/го, управление роботом, настройка систем рекомендаций.

>[!question]- 4. Объяснить различие между задачами классификации и регрессии. Какие метрики качества используются в этих задачах (Accuracy, Precision, Recall, F1, MAE, RMSE, R2)?
>
> - **Классификация** — правильно определить метку (категорию) класса. Пример: спам/не спам, определение объекта на изображении.
> - **Регрессия** — предсказание непрерывного числового значения. Пример: прогноз цены квартиры по ее характеристикам.
> 
> **Пример для наглядности:**
>
> - **Регрессия:** предсказать **цену** дома на основе его характеристик (площадь, район, год постройки).
> - **Классификация:** определить **тип** дома (новостройка/старый фонд) на основе его цены и других характеристик.
> 
> **Метрики качества:**
> ***Метрики для классификации***
>
>| Метрика | Формула | Описание |
|:--- | :--- | :--- |
| **Accuracy** | $\frac{TP + TN}{TP + TN + FP + FN}$ | Доля верно предсказанных объектов. Хороша на сбалансированных данных. |
| **Precision** | $\frac{TP}{TP + FP}$ | Доля истинно положительных среди всех объектов, которые модель назвала положительными. "Насколько мы можем доверять, когда модель говорит 'да'?" |
| **Recall** | $\frac{TP}{TP + FN}$ | Доля реально положительных объектов, которые модель обнаружила. "Какую часть всех реальных 'да' мы нашли?" |
| **F1-Score** | $2 \times \frac{P \times R}{P + R}$ | Гармоническое среднее Precision и Recall. Балансирует оба показателя. |
>
>***Метрики для регрессии***
>
> | Метрика | Формула | Описание |
| :--- | :--- | :--- |
| **MAE** |  $\frac{1}{n} \sum_{i=1}^{n} \| y_i - \hat{y}_i \|$ | Средняя абсолютная ошибка. Проста для интерпретации. |
| **RMSE** | $\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$ | Среднеквадратичная ошибка. Штрафует за большие отклонения сильнее, чем MAE. |
| **R²** | $1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$ | Коэффициент детерминации. Показывает, насколько хорошо модель объясняет дисперсию данных по сравнению с простым средним. |
>
> **Интерпретация R²:**
>
> - **R² = 1** — идеальная модель.
> - **R² = 0** — модель работает не лучше, чем предсказание средним значением.
> - **R² < 0** — модель работает хуже тривиального предсказания.

>[!question]- 5. Объяснить смысл разбиения данных на обучающую, валидационную и тестовую выборки. Какую задачу решает каждая из этих частей?
>
> Разбиение данных — фундаментальная практика для оценки **способности модели к обобщению** (работе на новых данных) и борьбы с **переобучением**.
>
> | Выборка | Доля (примерно) | Задача |
| :--- | :--- | :--- |
| **Обучающая (Train)** | 60-70% | **Обучение модели.** На этих данных алгоритм непосредственно подбирает параметры (веса, коэффициенты). |
| **Валидационная (Validation)** | 15-20% | **Настройка гиперпараметров и выбор модели.** Оценка обобщающей способности *в процессе* обучения, чтобы вовремя остановиться или выбрать лучшую модель. |
| **Тестовая (Test)** | 15-20% | **Финальная оценка.** Имитация "боевых" условий. Используется **единожды** в самом конце для объективной оценки итоговой модели на данных, которых она "никогда не видела". |


>[!question]- 6. Что такое переобучение и недообучение модели? Как они проявляются на графике зависимости ошибки от сложности модели на обучающей и валидационной выборках?
>
> | | Переобучение (Overfitting) | Недообучение (Underfitting) |
| :--- | :--- | :--- |
| **Суть** | Модель слишком сложна и "запомнила" обучающие данные, включая шум и выбросы. Не может обобщать. | Модель слишком проста и не уловила основные закономерности в данных. |
| **Причины** | Избыток параметров, мало данных, слабая регуляризация, слишком долгое обучение. | Недостаток параметров, слишком сильная регуляризация, мало признаков. |
| **Ошибка на обучении** | **Очень низкая** (может стремиться к 0) | **Высокая** |
| **Ошибка на валидации** | **Высокая** (значительно выше, чем на обучении) | **Высокая** (близка к ошибке на обучении) |
>
> **График зависимости ошибки от сложности модели**
>
> ![400](https://neerc.ifmo.ru/wiki/images/1/18/Bias-Variance-Tradeoff.png)
>
> - **Зона недообучения:** Обе ошибки (обучения и валидации) высоки и близки.
> - **Оптимальная сложность:** Ошибка валидации достигает минимума.
> - **Зона переобучения:** Ошибка обучения продолжает падать, а ошибка валидации — расти. Кривые расходятся.

>[!question]- 7. Дать определение признаков (features) и целевой переменной (label/target). Что такое предобработка признаков и feature engineering? Привести примеры.
>
> - **Признаки (Features)** — это входные переменные, характеристики объектов, на основе которых модель делает предсказания.
> - **Целевая переменная (Label/Target)** — это то, что мы хотим предсказать, выход модели, зависимая переменная.
>
> **Предобработка признаков (Feature Preprocessing)**
>
> Технический этап подготовки "сырых" данных к подаче в модель. Цель — исправить проблемы и привести данные к виду, понятному алгоритмам.
>
> **Примеры:**
>
> 1. **Обработка пропусков:** удаление строк, заполнение средним/медианой.
> 2. **Кодирование категориальных признаков:**
> 	- **Label Encoding:** ["низкий", "средний", "высокий"] → [0, 1, 2]
> 	- **One-Hot Encoding:** Цвет ["красный", "синий"] → `is_red: [1, 0]`, `is_blue: [0, 1]`.
> 	- **Word Embeddings:** преобразование слов в векторы с сохранением семантики.
> 3. **Масштабирование:** `StandardScaler` (mean=0, std=1) или `MinMaxScaler` ([0, 1]).
> 4. **Обработка выбросов:** обрезание, winsorization.
> 5. **Преобразование распределений:** логарифмирование для скошенных данных.
> 
> **Feature Engineering**
> 
> Творческий этап создания **новых признаков** из существующих или внешних данных, чтобы помочь модели лучше выявить закономерности.
> 
> **Примеры:**
>
> - **Из даты:** извлечение дня недели, месяца, является ли выходным.
> - **Из текста:** создание признаков "длина текста", "количество определённых слов".
> - **Взаимодействие признаков:** умножение "площади" на "цену за кв.м.".

>[!question]- 8. Описать алгоритм k-ближайших соседей для задачи регрессии: формула предсказания при равномерных весах и при весах, зависящих от расстояния, роль метрики и гиперпараметра k.
>
> Алгоритм **k-NN для регрессии** предсказывает значение для нового объекта как агрегацию (обычно среднее) значений его `k` ближайших соседей в пространстве признаков.
>
> **1. С равномерными весами (Uniform)**
>
> Предсказание — простое среднее арифметическое целевых значений `k` соседей.
>
> $\hat{y}(x_{\text{new}}) = \frac{1}{k} \sum_{i=1}^{k} y_i$
> 
> ***Пример***
> Цены 5 ближайших квартир: `[8, 9, 10, 11, 12]` млн руб.
> `ŷ = (8+9+10+11+12) / 5 = 10` млн руб.
>
> ***2. С весами, зависящими от расстояния (Weighted)***
>
> Близкие соседи вносят больший вклад. Вес $w_i$ обратно пропорционален расстоянию $d_i$ (часто $w_i = \frac{1}{d_i}$).
>
> ***Пример***
> Если ближайшая квартира (8 млн) в 0.1 км, а самая дальняя (12 млн) — в 1 км, то предсказание сместится к 8 млн.
>
> ***Роль метрики расстояния***
>
> Определяет понятие "близости" объектов. Разные метрики дают разных соседей.
>
> - **Евклидова:** $\sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}$ — стандартный выбор для непрерывных признаков.
> - **Манхэттенская:** $\sum_{i=1}^{n} |x_i - y_i|$ — устойчивее к выбросам.
> - **Косинусная:** $1 - \cos(x, y)$ — для текстов, важна направленность векторов.
>
> **Важно:** Перед использованием k-NN признаки необходимо **масштабировать**, иначе признак с большим размахом (например, зарплата) будет доминировать в расстоянии.
> 
> **Роль гиперпараметра `k`**
>
> - **Малое `k` (k=1):** Модель становится чувствительной к шуму и выбросам → высокий риск **переобучения**.
> - **Большое `k`:** Предсказание становится более сглаженным, но может игнорировать локальные особенности → риск **недообучения**.
> - **Выбор `k`:** Оптимальное значение подбирается на **валидационной выборке**.

# Лекция 2. Линейная регрессия, Ridge и Lasso

**Общее про регуляризацию:**

Регуляризация необходима для того, чтобы снизить риски переобучения. Когда модель переобучена, некоторые ее веса огромные по модулю, таким образом модель очень "извилистая". А регуляризация применяет штраф на эти веса (или же излишнюю сложность) и модель становится более гладкой.

  

![400](https://deepmachinelearning.ru/assets/images/under-overfitting-9c300b48dd2371dbcd5bd2fda7a930e9.png)

  

>[!question]- 3. Записать функционал Ridge-регрессии (L2-регуляризации) и объяснить, как L2-штраф влияет на значения коэффициентов и устойчивость модели.
>
> **Формула L2**
>
> $$J_{\text{ridge}}(\mathbf w,b)=\operatorname{MSE}(\mathbf w,b) + \lambda\,\lVert\mathbf w\rVert_2^2 = \operatorname{MSE}(\mathbf w,b) + \lambda\,\sum_{i=0}^{d} w_{i}^2$$
>
> Задача: минимизация $J_{\text{ridge}}$
>
>- Штраф $\lVert\mathbf w\rVert_2^2$ - сумма квадратов весов
> - $\lambda$ > 0 - коэффициент регуляризации. Регулирует на сколько сильно мы штрафуем веса.
> 	- Слишком большая лямбда - слишком маленькие веса (недообучение).
> 	- Слишком маленькая лямбда - тогда она плохо регуляризирует, большие веса остаются (переобучение).
> 	
> **Эффект от штрафов:**
> - Штраф на крупные веса, сглаживание, коэффициенты "сжимаются" к нулю
> - Не обнуляет коэффициенты
> - Уменьшает дисперсию модели (оценок коэффициентов)
> - Устойчивость к шуму и мультиколлинеарности
> - Уменьшает переобучение
> - Делит веса между коррелирующими признаками
> - См. геометрическую интерпретацию ниже.
>
> Мультиколлинеарность - это когда две переменные сильно коррелируют (тесно связаны) друг с другом

  >[!question]-  4. Записать функционал Lasso-регрессии (L1-регуляризации) и объяснить, почему L1-штраф часто приводит к появлению нулевых коэффициентов (разреженности модели).
>
> **Формула L1**
> $$J_{\text{lasso}}(\mathbf w,b)=\operatorname{MSE}(\mathbf w,b) + \lambda\,\lVert\mathbf w\rVert_1 = \operatorname{MSE} + \lambda\sum_i |w_i|.$$
> 
> Задача: минимизировать $J_{\text{lasso}}$
> - Штраф $\,\lVert\mathbf w\rVert_1$ - сумма абсолютной величины весов
> - Зависимость от $\lambda$ такая же, как в L2
> 
> Но Lasso может занулять некоторые признаки что приводит к обнулению некоторых признаков (разреженное решение). См. геометрическую интерпретацию ниже.
>
> **Эффект от штрафов**
> - то же самое, что и в L2, кроме:
> 	- обнуляет коэффициенты
>	- Часто выбирает один признак среди коррелирующих

>[!question]-  5. Сравнить Ridge и Lasso-регрессии: в каких ситуациях предпочтителен каждый из методов, что такое Elastic Net и как он сочетает L1 и L2-штрафы.
> 
> **Геометрическая интерпретация**
>
> ![400](https://i.imgur.com/MXWq02S.png)
> - Синее - наши веса
> - Красное - MSE
> - Черная точка - решение
> 
> 1. Из-за модулей у нас в L1 веса в виде ромбиков , а в L2 в виде окружности.
> 2. В L1 из-за углов ромба решение часто попадает в вершину, и тогда некоторые веса становятся нулем.
> 3. В L2 все веса умеренные по длине.
>
> **Ridge**:
>
> - много слабых признаков
> - важно стабилизировать веса
>
> **Lasso:**
>
> - мало важных признаков
> - интерпретируемость
>
> **Elastic Net:**
> $$\operatorname{MSE}(\mathbf w,b) + \lambda_1\lVert w\rVert_1 + \lambda_2\lVert w\rVert_2^2$$
> - Комбинация L1 и L2
> - $\lambda_1 = 0$ - применяем только Ridge,
> - $\lambda_2 = 0$ - применяем только Lasso
> 
> Используя Elastic Net, мы и убираем ненужные признаки, и уменьшаем переобучение. Разреженность + устойчивость. Используется когда много признаков и корреляций.

  

>[!question]- 6. Объяснить, зачем перед применением регуляризованных моделей стандартизуют признаки. Как на практике подбирают параметр регуляризации ?
>
> **Стандартизация**
> Стандартизируя признаки, мы делаем их "безразмерными". Иными словами, регуляризованные модели чувствительны к масштабу, что может привести к неверному штрафу весов, и, соответсвенно, коэффициентам.
> 
> **Подбор параметра $\lambda$**
>
> 1. Кросс-валидация или train/validation/test
> 2. Стандартизация
> 3. Проверка пере/недообучения по кривым валидации
> 4. Попробовать и Ridge, и Lasso, сравнить их по валидации.
> 5. Выбираем $\lambda$ с минимальной ошибкой
> 6. Кривая валидации - для каждого $\lambda$ обучаем модель и считаем ее ошибку на train и validation, строим график.
>
> Еще можно использовать поиск по сетке (GridSearch)
>
> **Примеры скейлеров**
>
> StandardScaler() - удаляет среднее значение и масштабирует данные до единичной дисперсии
> MinMaxScaler() - масштабирует все признаки данных в диапазоне [0, 1]

# Лекция 3. Логистическая регрессия
>[!question]- 3. Записать и\_ли объяснить выражение для вероятности наблюдения у є {0,1} при фиксированном х и параметрах модели. Записать и\_ли объяснить правдоподобие выборки как произведение по объектам¹.
>
> **Распределение Бернулли**
> У эксперимента есть два исхода - успех или неуспех. Мы хотим получить вероятность успеха ($y=1$)
> $$\hat p=\Pr(y=1\mid\mathbf x)$$
> **Сигмоида**
> Сигмоида задает параметр распредления Бернулли, и в отличие от линейной регрессии, на выход выдается вероятность $$\hat p = \sigma(z)\in[0,1]$$
> $$\sigma(z) = \frac{1}{1 + e^{-z}}\, , \qquad $$
> $$ z = \mathbf w^\top \mathbf x + b = \sum_{j=1}^{d} w_j x_j + b \in (-\infty, +\infty) $$
> - z - линейный отклик; 
> - x - вектор признаков; 
> - w - вектор весов; 
> - b - свободный член
> Подробнее про это есть в билете 2.1
>
> Сигмоида превращает неограниченный $z$ в вероятность, делая плавный переход между 2-мя классами. Чем дальше от границы решений ($z=0$) , тем выше уверенность.
> Крутая картинка сигмоиды:
> ![240](https://www.dmitrymakarov.ru/wp-content/uploads/2021/10/sigmoid-1024x523.png)
> По оси абсцисс - $z$, по оси ординат - $\sigma(z)$
> 
> **Выражения вероятности**
> - Для одного примера (стандартная форма распределения Бернулли):
> $$ p(y\mid \mathbf x) = \sigma(z)^y\, \bigl(1-\sigma(z)\bigr)^{(1-y)}, \quad y\in\{0,1\}. $$
> - y - правильный ответ
> - $\sigma(z)\,$- вероятность класса 1
> - $\bigl(1-\sigma(z)\bigr)$ - вероятность класса 0
> - Степени $y$ и $(1-y)$ "включают" или"выключают" множитель.
>
> Эта форма универсальна для обоих классов и используется при максимизации правдоподобия.
> После перемножения мы получаем вероятность класса.
> 
> - Для всей выборки (независимость примеров):
>
> $$ \mathcal L(\mathbf w,b) = \prod_{i=1}^n \sigma(z_i)^{y_i}\, \bigl(1-\sigma(z_i)\bigr)^{(1-y_i)}, $$
> $$ \quad z_i=\mathbf w^\top\mathbf x_i+b$$
> Перемножаем результат для одно объекта со всеми остальными, чтобы получить вероятность(правдоподобие) для всей выборки. Это значение мы хотим максимизировать.

>[!question]- 4. Вывести, привести и\_ли объяснить выражение для функции потерь логистической регрессии (log loss)¹.
> **Вывод log loss** (кросс-энтропийная потеря)
> 
> Log loss выводится из правдоподобия.
>
> 1) Логарифмируем произведение (сумма логов), т.к.:
>
> 	- после перемножения чисел от 0 до 1 итоговое произведение будет очень маленьким (при большой выборке)
> 	- работать с суммами гораздо удобнее чем с произведением.
> 	- суммы лучше дифференцируются, эффективный градиентный спуск 
> 	- $y_i$, которое стояло в степени, выносится по свойству логарифмов.
> 	$$
> 	\begin{equation*}
> 	\log \mathcal L = \sum_{i=1}^n \Bigl[ y_i\,\log\sigma(z_i) + (1-y_i)\,\log\bigl(1-\sigma(z_i)\bigr) \Bigr].
> 	\end{equation*}$$
> 2) Меняем знак, добавляем минус (минимизация вместо максимизации)
> -  Добавляем также усреднение по количеству объектов.
> 	$$ J(\mathbf w,b) = -\,\frac{1}{n}\sum_{i=1}^n \Bigl[ y_i\,\log\sigma(z_i) + (1-y_i)\,\log\bigl(1-\sigma(z_i)\bigr) \Bigr].$$
> Log loss мы хотим минимизировать, а правдоподобие максимизировать.

>[!question]- 5. Пояснить, как и зачем добавляются L1- и L2-регуляризации в логистическую регрессию. Как регуляризация влияет на переобучение и интерпретируемость модели?
>
> Всё то же самое, как и с LinReg
> Подробнее можно почитать в лекции 2 вопросы 3-6
> **Регуляризациия нужна чтобы:**
> - избежать переобучения
> - стабилизировать веса
> $$J_{\text{ridge}} = J + \lambda\,\lVert\mathbf w\rVert_2^2, \qquad$$
> $$J_{\text{lasso}} = J + \lambda\,\lVert\mathbf w\rVert_1$$
>
> **Интерпретируемость**
> - L1 повышает интерпретируемость, тк уменьшает количество признаков
> - L2 учитывает все признаки, сложнее понять какие действительно важны

# Лекция 4. Решающие деревья и ансамбли (бэггинг, случайные леса, стэкинг)


# Лекция 5. Бустинг и градиентный бустинг над деревьями
>[!question]- 1. Сформулировать общую идею бустинга. Чем бустинг принципиально отличается от бэггинга и стэкинга?
>
> **Общая идея**
> 
> Последовательное добавление слабых моделей, каждая из которых исправляет ошибки предыдущей, i.e. предсказывает ошибку предыдущей.
>
> ***Отличие от бэггинга и стэкинга***
>   
> При бэггинге обучется несколько моделей, и финальное предсказание формируется "голосованием" (берется мода или среднее от всех предсказаний)
> При стэкинге на предсказаниях нескольких моделей обучается еще одна модель, которая сможет лучше комбинировать их ответы, чем просто мода или среднее.
> При бустинге же модели работают как бы не параллельно, а последовательно. Каждая последующая модель, кроме первой, старается предсказать не таргет переменную, как в бэггинге или стэкинге, а ошибку предыдущей модели.
> Бэггинг и стэкинг менее чувствительны к отдельным выбросам. Бустинг чувствителен к шуму (важна регуляризация).

>[!question]- 2. Записать и_ли объяснить объяснить общее обновление модели в градиентном бустинге [1]
> $$ F_{M}(x) = F_{M-1}(x) + v*h_{m}(x) $$
> 
> Где 
> - $F_{0}(x)$ - изначальная модель, которая грубо предсказывает ошибку
> - $h_{M}(x)$ - модель, которая предсказывает ошибки $F_{M-1}(x)  
> - $v \in (0; 1]$ - скорость обучения (i.e. как сильно модель каждой итерации влияет на конечную модель. Чем меньше  скорость обучения, тем больше нужно обучить моделей, но тем более точно можно скорректировать финальную модель)
> 
> Оно же:
> 
> $$ F(x) = F_{0}(x) + \sum_{i=1}^{h} h_{i}(x) * v^i $$

>[!question]- 3. Пояснить точку зрения градиентного спуска в пространстве функций: как задается функционал ошибки L(F) и какую роль играют псевдо-остатки (антиградиенты) на обучающих объектах.
>
> **Пространство функций**
>
> Пространство функций - это множество слабых функций h, которые мы перебираем для нахождения лучшей финальной функции F
>
> **Как задается функционал ошибка L(F)**
> 
> $$ L(F) = \sum_{i=1}^{n}l(y_{i}, F(x_{i})) $$
> 
> Где F - искомая функция, а l - выбранная функция потерь.
> 
>  **Псевдо-остатки**
>  
>  На каждом шаге нам нужна модель h, которая будет предсказывать ошибку прошлой модели F. 
> 
>  $$ g_{im} = \frac{\partial l(y_{i}, F_{m-1}(x_{i}))}{\partial F_{m-1}(x_{i})} $$
>  
>  $$ h_{m} \approx -g_{im} $$
>  
>  I.e. псевдо-остатки (производная Фреше в обобщенном метрическом пространстве) пропорциональны предсказаниям модели h.
>  
>  Градиентный бустинг называется так, т.к. формула сильно похожа на формулу градиентного спуска
>  
>  $$ x = x_{0} - \sum_{i=1}^{n} v_{i} g_{'}(x_{i}) $$

> [!question]- 4. Записать и_ли объяснить шаг алгоритма градиентного бустинга над деревьями: вычисление псевдо-остатков, обучение регрессионного дерева по этим значениям, поиск оптимальных сдвигов по листам и обновление ансамбля [1]
> 
> 1. Вычисление псевдо-остатков $$ r_{im} = \frac{\partial l(y_{i}, F_{m-1}(x_{i}))}{\partial F_{m-1}(x_{i})} $$
> 2. Обучение регрессионного дерева $h_{m}(x)$ по парам ($x_{i}$, $r_{im}$)
> 3. Нахождение оптимального сдвига (константы) по листам: для каждого листа $R_{jm}$ $$ γ_{jm} = arg\min_{γ} \sum_{x_{i} \in R_{jm}} l(y_{i}, F_{m-1}(x_{i}) + γ) $$
> 4. Обновление модели $$ F_{m}(x) = F_{m-1}(x) + v * \sum_{j} γ_{jm} 1\{x \in R_{jm} \} $$

>[!question]- 5. Перечислить основные способы регуляризации в градиентном бустинге: малая скорость обучения v, ограничение глубины деревьев, минимальный размер листа, субсемплинг объектов, субсемплинг признаков, ранняя остановка по валидационной выборке.
>
> 1. Скорость обучения (shrinkage)  $v \in (0; 1]$. Чем меньше, тем устойчивее, но нужно больше деревьев.
> 2. Глубина дерева / число листьев: неглубокие деревья (3-8 уровней) приводят к слабым базовым моделям.
> 3. Субсемплинг объектов: обучение $h_{m}$ на случайной доле данных (обычно от 0.5 до 0.9)
> 4. Субсемплинг признаков: случайный поднабор признаков на сплите/уровне/дереве.
> 5. Минимальный размер листа, L2-штраф на веса листок, макс. число узлов.
> 6. Ранняя остановка по валидации: мониторинг метрики и прекращение роста M (перетекает в некст вопрос)

>[!question]- 6. Объяснить, как по поведению метрик на обучающей и валидационной выборках диагностировать переобучение бустинговой модели и как выбирать оптимальное число итераций.
>
> **Переобучение**
> 
> При подборе гиперпараметров нужно стремиться к уменьшению метрики на валидации и сохранению метрики на обучающей выборке. Если материка на обучающей выборке уменьшается, а на валидационной - нет, то это признак переобучения.
> 
> **Число итераций**
> 
> Подбирается так же, как и любой гиперпараметр, - по метрике валидационной выборке

# Лекция 6. Кластеризация, SVD и PCA
>[!question]- 1.  Дать определение обучению без учителя. Какие задачи обычно относят к обучению без учителя? Приведите примеры.
> **Определение**
> Обучение без учителя - это метод машинного обучения, при котором алгоритм работает с неразмеченными данными (отсутствие таргет-переменной, $y$) с целью обнаружить, как организованы данные.
> 
> **Примеры**
> Примерами являются: понижение размерности (матриц из данных) и кластеризация (разбиение данных на кластеры)
> 
> Примеры в реальной жизни: Геологическое обнаружение минералов, кластеризация генов, машинное зрение.

>[!question]- 2. Описать алгоритм K-Means. Записать и объяснить целевую функцию, которую алгоритм минимизирует
>
> **Алгоритм**
> 1. Выбирается K случайных (или по какому-то алгоритму) стартовых точек (центроидов)
> 2. Каждый элемент данных относится к тому же “кластеру”, что и ближайшая стартовая точка 
> 3. В каждом созданном кластере выбирается самый средний элемент - он будет выступать новым центроидом. Для новых центроидов снова выполняем пункт 2.
> 4. Повторяем пункты 2-3 до тех пор, пока кластеры практически не перестанут менятся
>
> **Минимизируемая функция**
>
> $$ J(C, \mu) = \sum_{k=1}^{K} \sum_{\mathbf{x}_i \in C_k} \|\mathbf{x}_i - \boldsymbol{\mu}_k \|^2 $$
> 
> Где
> - $x_{i}$ - точка
> - $\mu_{c(i)}$ - центр ее кластера
>
> То есть сумма от сумм расстояний каждого объекта до центроида  для каждого кластера. Все расстояния суммируем для кластера а потом и все кластеры суммируем

>[!question]- 3. Перечислить основные преимущества и недостатки K-Means. Как влияет масштабирование признаков и наличие выбросов на работу алгоритма?
>
>**Плюсы**
> 1. Быстрый (по сравнению с двумя другими известными алгоритмами) - асимптотическая сложность ниже ($n* k * d * t$ против кубических и квадратных), при этом операции вычисления оптимизированы под устройство процессора (векторные регистры)
> 2.  Масштабируемость на размеры - $O(n) = n*k*d*t$, где k - количество центроидов, d - длина векторов (features), t - количество итераций
> 2. Интерпретируемый - результатом становятся вполне объяснимые центры и близкие к ним данные
> 
> **Минусы**
> 1. Немасштабированные данные сильно ухудшают работоспособность, так как признаки с большим разбросом данных (большой масштаб) будут важнее более плотных
> 2. Выбросы также ломают модель, так как минимизируемая функция - квадрат расстояний, соответственно новый центроид будет сильно сдвинут

>[!question]- 4. Объяснить алгоритм DBSCAN. Каковы роли параметров e (epsilon) и min_samples? Чем отличаются ядровые, пограничные и шумовые точки?
> **Идея**
> 
> Кластерами будут зоны “высокой плотности” объектов, которые разделены границами - зонами “низкой плотности”.
> 
> **Алгоритм**
> 1. Выбираем произвольную точку.
> 2. Берём всех соседей в e (epsilon)-окрестности. 
> 3. Если количество соседей >= min_samples - в этой точке считаем новый кластер.
> 4. Если соседей меньше min_samples или точка не принадлежит уже созданному кластеру, то точка помечается как шум
> 5. Проходим также все оставшиеся точки.
>
> **Ядровые, пограничные и шумовые точки**
> 
> Ядровые - принадлежащие “внутренней” части обнаруженного кластера, не участвуют в обновлении новых точек.
> 
> Пограничные - точки на “границе” кластера - через них и epsilon и высчитывается принадлежность следующих точек.
> 
> Шумовые - помеченные как шум.

>[!question]- 5. Сравнить DBSCAN и K-Means по форме находящихся кластеров, устойчивости к выбросам, необходимости заранее задавать число кластеров и чувствительности к плотности данных?
>
> **Форма**
> 
> - K-Means - n-мерная сфера (окружность, при двух признаках), так как принадлежность определяется расстоянием до центра (центроида)
> - DBSCAN - произвольная форма, так как “расширение” кластера происходит засчёт граничных точек (ближайшие к границе)
>
> **Устойчивость к выбросам**
>
> - K-Means - отсутствует, так как выбросы сильно смещают центроиды (см. выше про квадрат расстояний)
> - DBSCAN - Высокая, так как способен различать шумы
>
> **Число кластеров**
> 
> - K-Means: заданное, K
> - DBSCAN: сам определяет их
>
>**Чувствительность к плотности данных**
>
> - K-Means: он игнорирует локальную плотность, разделяет зоны на равные по удалённости
> - DBSCAN: алгоритм основан на плотности, а потому равноплотные данные ухудшают работоспособность

>[!question]- 6. Описать идею агломеративной иерархической кластеризации: начальное состояние, правило слияния кластеров, возможные варианты связи (single, complete, average, Ward), роль дендрограммы.
>
> **Идея**
> 
> Не разделять данные на кластера сразу, а объединять близкие малые кластеры для получения больших. Принцип “снизу-вврех”.
>
> **Начальное состояние**
> 
> Важдый объект из выборки - кластер (всего их n)
>
> **Правило слияния** 
> 
> Выбираем у каждого кластера ближайший в соответствии с выбранным вариантом связи, объединяем их. Затем повторяем слияние новых кластеров с пересчитанным расстоянием
> 
> **Варианты связи**
> 
> - Single - расстояние между ближайшими точками кластеров
> - Complete - между самыми далёкими элементами
> - Average - между средними, “центрами” кластеров
> - Ward - сложный вид, на доп вопрос (кратко - минимизация внутрикластерной дисперсии)
>
> **Дендрограмма**
>
> Дендрограмма - древовидная диаграмма, которая визуализирует слияние малых кластеров (листьев) в конечные кластера. Уровень, на котором будет сделан “срез” диаграммы отсекает количество итоговых кластеров.

>[!question]- 7. Перечислить достоинства и недостатки иерархической кластеризации, в том числе с точки зрения вычислительной сложности и работы с большими выборками
>
> **Достоинства**
> 
> 1. Интерпретируемость. Наглядно показывает вложенность данных внутри кластера
> 2. Не требует задавать число кластеров, однако необходимо выбрать уровень детализации (уровня отсечения разных кластеров)
> 3.  Результат воспроизводимый, так как объединение кластеров не зависит от “случайности”
>
> **Недостатки**
>
> 1. Затрачивает много памяти (необходимо хранить расстояние между всеми парами значений)
> 2. Чувствителен к шуму. Объединение с близким шумовым объектом на раннем этапе ведёт к “связыванию” кластера с шумом
> 3. Необходимо выбирать метод связи - от этого зависит результат.
> 4. Не учитывает, что данные могут быть разбросаны произвольно, а не сферически-подобно
>
> ***Особенные недостатки***
> 
> 5. Как и с памятью, необходимо делать очень много вычислений $O(n) = n^3$ => долго
> 6. Из-за такой высокой асимптотической сложности, физически не способен кластеризировать выборки размером более 10^6 (или больше)

> [!question]- 8. Сформулировать основные цели снижения размерности и назвать несколько наиболее популярных алгоритмов.
> 
> **Цели**
> - Убрать мультиколениарные (говорящие об одном и том же, коррелирующие) признаки
> - Избавится от шумов (избавление от случайных значений
> - Решает проблему [проклятия размерности](https://en.wikipedia.org/wiki/Curse_of_dimensionality) (чем больше фич - тем труднее модели обучатся и легче переобучаться)
> - Ускорение работы моделей, обучаемых на данных: меньше фич -> меньше вычислений
> - Позволяет визуализировать данные. Например, в рамках кластеризации помогает преобразовать многомерное пространство в 2/3-мерное (чтобы наглядно увидеть распределение данных)
> - Сжимает данные -> меньше памяти
> - Выявление скрытых (латентных) признаков
>    
> **Популярные алгоритмы**
> (в подробностях - на доп вопрос, помните название только)
> 
> - PCA (Principal Component Analysis) - суть: преобразовать в новые оси (из многомерности в n-мерность), максимизируя при этом дисперсию (чтобы значение признака было говорящим)
> - SVD (Singular Value Decomposition) - матричная факторизация. Буквально поворот матрицы и умножение на саму себя для сжатие размерности (матрица размера $n*m$ становится матрицей размера $\min(n, m)^2$)
> - *t-SNE (t-distributed stochastic neighbour embedding) - один из нелинейных методов снижения размерности