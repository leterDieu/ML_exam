# Лекция 1. Введение в машинное обучение

> [!question]- 1. Дать определение задачи машинного обучения. Что такое обучающая выборка, модель и функция потерь?
> ***Определение задачи машинного обучения***
>> Задача машинного обучения — это задача автоматического **выявления закономерностей** (зависимостей) в данных с помощью специальных алгоритмов (моделей) и их последующего использования для **прогнозирования** или **принятия решений** на новых, ранее не встречавшихся данных.
>>
>> Формально: по заданной **выборке данных** $( D = \{ (\mathbf{x}_i, y_i) \}_{i=1}^n )$ (обучающей выборке) найти **функцию** $( f: \mathcal{X} \to \mathcal{Y} )$, которая наилучшим образом приближает неизвестную целевую зависимость $( y = f^*(\mathbf{x}) )$, где $( \mathbf{x} \in \mathcal{X} )$ — объект (признаковое описание), $( y \in \mathcal{Y} )$ — целевая переменная (ответ).
>
> ***Ключевые компоненты***
>>
>> 1.  **Обучающая выборка (training dataset)**:
>>     - Конечное множество **пар «объект–ответ»** $( \{ (\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \dots, (\mathbf{x}_n, y_n) \} )$, используемое для настройки (обучения) модели.
>>     - **Объект (пример)** $( \mathbf{x}_i )$ — вектор признаков (features), описывающий i-й объект. Может быть представлен как точка в $( \mathbb{R}^m )$ (если $( m )$ признаков).
>>     - **Ответ (target)** $( y_i )$ — значение целевой переменной, которое модель должна научиться предсказывать.
>>
>> 2.  **Модель (model)**:
>>     - Математическая форма зависимости между признаками объекта и целевой переменной.
>>     - Обычно задаётся **параметрическим семейством функций** $( f(\mathbf{x}; \theta) )$, где $( \theta )$ — вектор параметров модели.
>>     - **Цель обучения** — найти такие значения параметров $( \theta )$, при которых модель $( f(\mathbf{x}; \theta) )$ наилучшим образом описывает данные обучающей выборки.
>>     - **Примеры моделей**: линейная регрессия, логистическая регрессия, решающее дерево, нейронная сеть.
>>
>> 1.  **Функция потерь (loss function)** $( L(f(\mathbf{x}; \theta), y) )$:
>>     - Функция, которая **измеряет ошибку** (стоимость) предсказания модели на одном объекте. Она оценивает, насколько предсказание $( \hat{y} = f(\mathbf{x}; \theta) )$ отличается от истинного ответа \( y \).
>>     - **Основное требование**: чем больше ошибка, тем больше значение функции потерь.
>>
>>     **Эмпирический риск (empirical risk)** — средняя ошибка модели на всей обучающей выборке:
>>     $$ Q(\theta) = \frac{1}{n} \sum_{i=1}^{n} L(f(\mathbf{x}_i; \theta), y_i) $$
>>
>>     - **Цель обучения в терминах функции потерь** — найти параметры $( \theta )$, минимизирующие эмпирический риск (принцип минимизации эмпирического риска):
>>     $$ \theta^* = \arg\min_{\theta} Q(\theta) $$
>
> ***Примеры функций потерь***
>> - Для **регрессии** (непрерывный $( y )$): **MSE** (среднеквадратичная ошибка), $( L(\hat{y}, y) = (\hat{y} - y)^2 )$.
>> - Для **бинарной классификации** (дискретный $( y \in \{0, 1\} )$): **Log Loss** (логистическая потеря), $( L(\hat{p}, y) = -[y \log(\hat{p}) + (1-y) \log(1-\hat{p})] )$, где $( \hat{p} )$ — вероятность класса 1.
>> - Для **многоклассовой классификации**: **Cross-Entropy Loss** (перекрёстная энтропия).
>
> ***Схема процесса машинного обучения (кратко)***
>> 1.  **Задаём модель** $( f(\mathbf{x}; \theta) )$ — гипотезу о виде искомой зависимости.
>> 2.  **Выбираем функцию потерь** \( L \), адекватную задаче (регрессия/классификация).
>> 3.  **На обучающей выборке** ищем параметры $( \theta^* )$, минимизирующие среднюю ошибку $( Q(\theta) )$.
>> 4.  **Оцениваем качество** найденной модели на **тестовой выборке** (новые данные, не участвовавшие в обучении).

> [!question]- 2. Сформулировать математическую постановку задачи обучения с учителем: выборка $D = \{(x_i, y_i)\}_{i=1}^{n}$, поиск модели f(x), минимизирующей ошибку на данных.
> ***Математическая постановка задачи обучения с учителем***
>> Дана обучающая выборка: $D = \{(x_i, y_i)\}_{i=1}^{n}$, где:
>> - $x_i \in \mathcal{X}$ — признаковое описание i-го объекта
>> - $y_i \in \mathcal{Y}$ — целевая переменная (ответ) для i-го объекта
>>
>> Требуется найти функцию (модель) $f: \mathcal{X} \rightarrow \mathcal{Y}$ из некоторого семейства функций $\mathcal{F}$, которая минимизирует ожидаемую ошибку (риск):
>> $$ R(f) = \mathbb{E}_{(x,y) \sim P} [L(y, f(x))] $$
>> где $L(y, \hat{y})$ — функция потерь, измеряющая несоответствие между предсказанием $f(x)$ и истинным значением $y$.
>
> ***Практический подход (минимизация эмпирического риска)***
>> На практике минимизируется эмпирический риск на обучающей выборке:
>> $$ \hat{R}(f) = \frac{1}{n} \sum_{i=1}^{n} L(y_i, f(x_i)) $$
>> Цель — не просто "выучить" обучающие данные, а найти модель, способную к **обобщению** на новые, ранее не встречавшиеся данные.

> [!question]- 3. Перечислить основные типы задач машинного обучения (обучения с учителем, обучения без учителя, обучения с подкреплением) и привести по одному примеру из каждого типа.
> ***Основные типы задач машинного обучения***
>
>> **1. Обучение с учителем (Supervised Learning)**
>> *Алгоритму подается размеченная выборка (объект + ответ).*
>> - **Классификация**: предсказание категории/метки
>>   *Пример*: определение спама/не спама в письмах
>> - **Регрессия**: предсказание численного значения
>>   *Пример*: прогноз стоимости квартиры по её характеристикам
>
>> **2. Обучение без учителя (Unsupervised Learning)**
>> *Алгоритм работает с неразмеченными данными, ищет скрытые структуры.*
>> - **Кластеризация**: группировка похожих объектов
>>   *Пример*: сегментация клиентов по истории покупок
>> - **Снижение размерности**: уменьшение числа признаков
>>   *Пример*: PCA для визуализации многомерных данных
>
>> **3. Обучение с подкреплением (Reinforcement Learning)**
>> *Агент обучается, взаимодействуя со средой, получая награды/штрафы.*
>> *Пример*: обучение робота ходьбе или алгоритма для игры в шахматы

> [!question]- 4. Объяснить различие между задачами классификации и регрессии. Какие метрики качества используются в этих задачах?
> ***Различие между классификацией и регрессией***
>> **Классификация** — предсказание дискретной метки (категории). 
>> *Пример*: определение типа опухоли (доброкачественная/злокачественная).
>>
>> **Регрессия** — предсказание непрерывного числового значения.
>> *Пример*: прогноз стоимости акции на бирже.
>
> ***Метрики качества для классификации***
>> | Метрика | Формула | Описание |
>> |---------|---------|----------|
>> | **Accuracy** | $\frac{TP + TN}{TP + TN + FP + FN}$ | Доля верно предсказанных объектов |
>> | **Precision** | $\frac{TP}{TP + FP}$ | Точность — "Насколько можно доверять положительному прогнозу" |
>> | **Recall** | $\frac{TP}{TP + FN}$ | Полнота — "Какую часть реальных положительных нашли" |
>> | **F1-Score** | $2 \times \frac{P \times R}{P + R}$ | Гармоническое среднее Precision и Recall |
>
> ***Метрики качества для регрессии***
>> | Метрика | Формула | Описание |
>> |---------|---------|----------|
>> | **MAE** | $\frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$ | Средняя абсолютная ошибка |
>> | **RMSE** | $\sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$ | Среднеквадратичная ошибка (сильнее штрафует большие отклонения) |
>> | **R²** | $1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$ | Коэффициент детерминации |
>
> ***Интерпретация R²***
>> - **R² = 1** — идеальная модель
>> - **R² = 0** — модель работает не лучше простого среднего
>> - **R² < 0** — модель работает хуже тривиального предсказания

> [!question]- 5. Объяснить смысл разбиения данных на обучающую, валидационную и тестовую выборки.
> ***Назначение разбиения данных***
>> Разбиение данных — фундаментальная практика для оценки **способности модели к обобщению** (работе на новых данных) и борьбы с **переобучением**.
>
> ***Задачи каждой выборки***
>> | Выборка | Доля | Задача |
>> |---------|------|--------|
>> | **Обучающая (Train)** | 60-70% | **Непосредственное обучение модели**: подбор параметров (весов, коэффициентов) алгоритмом. |
>> | **Валидационная (Validation)** | 15-20% | **Настройка гиперпараметров и выбор модели**: оценка обобщающей способности *в процессе* обучения, ранняя остановка, выбор между разными моделями. |
>> | **Тестовая (Test)** | 15-20% | **Финальная, объективная оценка**: имитация "боевых" условий. Используется **единожды** в самом конце для оценки итоговой модели на данных, которые она "никогда не видела". |
>
> ***Важное правило***
>> Тестовая выборка должна использоваться **только один раз** в самом конце процесса. Её нельзя использовать для подбора параметров, иначе оценка будет оптимистически смещённой.

> [!question]- 6. Что такое переобучение и недообучение модели?
> ***Недообучение (Underfitting)***
>> **Суть**: Модель слишком проста и не улавливает основные закономерности в данных.
>> **Причины**: Недостаток параметров, слишком сильная регуляризация, мало признаков или слишком простая архитектура модели.
>> **Признаки**: Высокая ошибка как на обучающей, так и на валидационной выборке.
>
> ***Переобучение (Overfitting)***
>> **Суть**: Модель слишком сложна и "запомнила" обучающие данные вместе с шумом и выбросами, теряя способность к обобщению.
>> **Причины**: Избыток параметров, слишком долгое обучение, слабая регуляризация, мало данных относительно сложности модели.
>> **Признаки**: Очень низкая ошибка на обучении, но высокая ошибка на валидации.
>
> ***График зависимости ошибки от сложности модели***
>> ![Кривые обучения](https://neerc.ifmo.ru/wiki/images/1/18/Bias-Variance-Tradeoff.png)
>> - **Зона недообучения**: Обе ошибки (обучения и валидации) высоки и близки.
>> - **Оптимальная сложность**: Ошибка валидации достигает минимума.
>> - **Зона переобучения**: Ошибка обучения продолжает падать, а ошибка валидации растёт — кривые расходятся.

> [!question]- 7. Дать определение признаков и целевой переменной. Что такое предобработка признаков и feature engineering?
> ***Основные определения***
>> **Признаки (Features)** — входные переменные, характеристики объектов, на основе которых модель делает предсказания.
>> **Целевая переменная (Label/Target)** — то, что мы хотим предсказать, выход модели, зависимая переменная.
>
> ***Предобработка признаков (Feature Preprocessing)***
>> **Цель**: Техническая подготовка "сырых" данных к подаче в модель.
>> **Примеры**:
>> 1. **Обработка пропусков**: удаление, заполнение средним/медианой.
>> 2. **Кодирование категориальных признаков**: 
>>    - *Label Encoding*: ["низкий", "средний", "высокий"] → [0, 1, 2]
>>    - *One-Hot Encoding*: создание бинарных признаков для каждой категории.
>> 3. **Масштабирование**: 
>>    - *StandardScaler*: приведение к mean=0, std=1
>>    - *MinMaxScaler*: масштабирование в диапазон [0, 1]
>> 4. **Обработка выбросов**: обрезание, winsorization.
>> 5. **Преобразование распределений**: логарифмирование, Box-Cox.
>
> ***Feature Engineering***
>> **Цель**: Творческое создание **новых признаков** из существующих или внешних данных для лучшего выявления закономерностей.
>> **Примеры**:
>> 1. **Из даты**: день недели, месяц, время года, является ли выходным.
>> 2. **Из текста**: длина текста, количество определённых слов, тональность.
>> 3. **Взаимодействие признаков**: произведение "площади" на "цену за кв.м.", отношение признаков.
>> 4. **Агрегация**: средние/суммы по группам.

> [!question]- 8. Описать алгоритм k-ближайших соседей для задачи регрессии.
> ***Алгоритм k-NN для регрессии***
>> **Основная идея**: Предсказать значение для нового объекта как агрегацию значений его k ближайших соседей в пространстве признаков.
>
> ***Процесс предсказания***
>> 1. Для нового объекта $x_{\text{new}}$ находим k ближайших объектов в обучающей выборке.
>> 2. Используем значения целевой переменной этих соседей для формирования предсказания.
>
> ***Формулы предсказания***
>> **С равномерными весами (Uniform)**: 
>> $$ \hat{y}(x_{\text{new}}) = \frac{1}{k} \sum_{i=1}^{k} y_i $$
>> *Пример*: Цены 5 ближайших квартир: [8, 9, 10, 11, 12] млн руб. → $\hat{y} = (8+9+10+11+12)/5 = 10$ млн руб.
>>
>> **С весами, зависящими от расстояния (Weighted)**:
>> $$ \hat{y}(x_{\text{new}}) = \frac{\sum_{i=1}^{k} w_i y_i}{\sum_{i=1}^{k} w_i} $$
>> где $w_i = \frac{1}{d(x_{\text{new}}, x_i)}$ или $w_i = \exp(-d(x_{\text{new}}, x_i))$
>> *Близкие соседи вносят больший вклад в предсказание.*
>
> ***Роль метрики расстояния***
>> Определяет понятие "близости" объектов:
>> - **Евклидова метрика**: $\sqrt{\sum_{j=1}^{d} (x_j - y_j)^2}$ — стандартный выбор для непрерывных признаков.
>> - **Манхэттенская метрика**: $\sum_{j=1}^{d} |x_j - y_j|$ — устойчивее к выбросам.
>> - **Косинусная метрика**: $1 - \frac{x \cdot y}{\|x\| \|y\|}$ — для текстовых данных, важна направленность векторов.
>
> ***Важность масштабирования признаков***
>> Перед применением k-NN признаки необходимо **масштабировать**, иначе признак с большим размахом (например, зарплата) будет доминировать в расстоянии над признаками с малым размахом (например, возраст).
>
> ***Роль гиперпараметра k***
>> - **Малое k (k=1)**: Модель очень чувствительна к шуму и выбросам → высокий риск **переобучения**.
>> - **Большое k**: Предсказание становится более сглаженным, но может игнорировать локальные особенности → риск **недообучения**.
>> - **Оптимальное k**: Подбирается на **валидационной выборке** или с помощью кросс-валидации.
# Лекция 2. Линейная регрессия, Ridge и Lasso

> [!question]- 1. Записать модель линейной регрессии в векторной форме
> ***Базовая векторная форма***
>> Для одного объекта $x^{(i)} \in \mathbb{R}^n$:
>> $$ \hat{y}^{(i)} = \mathbf{w}^\top \mathbf{x}^{(i)} + b $$
>> где:
>> - $\mathbf{w} = [w_1, w_2, ..., w_n]^\top$ — вектор весов (коэффициентов)
>> - $\mathbf{x}^{(i)} = [x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)}]^\top$ — вектор признаков объекта
>> - $b$ — свободный член (смещение, intercept)
>> - $\hat{y}^{(i)}$ — предсказанное значение для $i$-го объекта
>
> ***Расширенная векторная форма (с включением $b$ в вектор весов)***
>> 1. Добавляем единицу к вектору признаков: $\tilde{\mathbf{x}}^{(i)} = [1, x_1^{(i)}, ..., x_n^{(i)}]^\top \in \mathbb{R}^{n+1}$
>> 2. Объединяем $b$ и $\mathbf{w}$: $\tilde{\mathbf{w}} = [b, w_1, ..., w_n]^\top \in \mathbb{R}^{n+1}$
>>
>> Тогда модель принимает чистую векторную форму:
>> $$ \boxed{\hat{y}^{(i)} = \tilde{\mathbf{w}}^\top \tilde{\mathbf{x}}^{(i)}} $$
>>
>> Это эквивалентно скалярному произведению расширенных векторов.
. Объяснить смысл параметров $\mathbf{w}$ и $b$
> ***Параметр $\mathbf{w}$ (вектор весов)***
>> - **Что это?**: Вектор коэффициентов $\mathbf{w} = [w_1, w_2, ..., w_n]^\top$, где каждый $w_j$ соответствует одному признаку $x_j$.
>> - **Геометрический смысл**: В пространстве признаков $\mathbb{R}^n$ вектор $\mathbf{w}$ является **нормалью** (перпендикуляром) к гиперплоскости регрессии $\mathbf{w}^\top \mathbf{x} + b = 0$. Он указывает направление наискорейшего роста $\hat{y}$.
>> - **Содержательный смысл**:
>>   - **Знак $w_j$** показывает характер влияния:
>>     - $w_j > 0$: с ростом $x_j$ значение $\hat{y}$ увеличивается (прямая зависимость)
>>     - $w_j < 0$: с ростом $x_j$ значение $\hat{y}$ уменьшается (обратная зависимость)
>>   - **Величина $|w_j|$** показывает силу влияния (при условии стандартизации признаков):
>>     - Чем больше $|w_j|$, тем сильнее изменение $x_j$ влияет на $\hat{y}$
>>
>> **Пример**: В модели цены квартиры $\hat{y} = 5.2x_{\text{площадь}} - 20x_{\text{до центра}} + b$:
>> - $w_{\text{площадь}} = 5.2 > 0$: цена растёт с площадью
>> - $w_{\text{до центра}} = -20 < 0$: цена падает с удалением от центра (сильное влияние: $|-20| > |5.2|$)
>
> ***Параметр $b$ (свободный член, intercept)***
>> - **Что это?**: Скалярная константа, не зависящая от признаков.
>> - **Геометрический смысл**: Параметр $b$ **сдвигает** гиперплоскость регрессии параллельно самой себе. Он определяет значение $\hat{y}$ при нулевых признаках.
>> - **Содержательный смысл**: Базовое (стартовое) значение целевой переменной, когда **все признаки равны нулю**.
>>
>> **Пример**: Если $b = 50$ в модели цены квартиры, то это означает:
>> - Гипотетическая квартира с нулевой площадью и расположенная в центре (нулевое расстояние) имела бы "базовую" стоимость 50 тыс.$
>> - На практике интерпретация $b$ имеет смысл только если ноль для всех признаков — осмысленная точка

> [!question]- 2. Сформулировать цель обучения линейной регрессии: какие параметры ищутся и по какому критерию они выбираются.
> ***Цель обучения***
>> Найти такие значения параметров модели (вектора весов $(\mathbf{w})$ и смещения $(b)$), которые минимизируют ошибку предсказаний модели на обучающих данных.
>
> ***Искомые параметры***
>> 1.  **Вектор весов (коэффициентов)** $(\mathbf{w} = [w_1, w_2, \dots, w_n]^\top)$, где $(n)$ — количество признаков.
>> 2.  **Свободный член (смещение, bias)** $(b)$ — скаляр.
>>
>> **В расширенной форме**:
>> Объединенный вектор параметров $(\tilde{\mathbf{w}} = [b, w_1, w_2, \dots, w_n]^\top)$.
>
> ***Критерий выбора параметров (Функция потерь)***
>> Параметры выбираются путем **минимизации функции среднеквадратичной ошибки (MSE)** — суммы квадратов разностей между истинными значениями целевой переменной $(y_i)$ и предсказанными значениями $(\hat{y}_i)$.
>>
>> **Формальная постановка задачи оптимизации**:
>> $$ \min_{\mathbf{w}, b} \text{MSE}(\mathbf{w}, b) = \min_{\mathbf{w}, b} \frac{1}{n} \sum_{i=1}^{n} \left( y_i - (\mathbf{w}^\top \mathbf{x}_i + b) \right)^2 $$
>>
>> где:
>> - $(n)$ — количество объектов в обучающей выборке,
>> - $(\mathbf{x}_i)$ — вектор признаков $(i)$-го объекта,
>> - $(y_i)$ — истинное целевое значение для $(i)$-го объекта.
>>
>> **В расширенной векторной форме**:
>> $$ \min_{\tilde{\mathbf{w}}} \text{MSE}(\tilde{\mathbf{w}}) = \min_{\tilde{\mathbf{w}}} \frac{1}{n} \sum_{i=1}^{n} \left( y_i - \tilde{\mathbf{w}}^\top \tilde{\mathbf{x}}_i \right)^2 $$
>> где $(\tilde{\mathbf{x}}_i = [1, x_{i1}, x_{i2}, \dots, x_{in}]^\top)$.
>
> ***Процесс обучения***
>> 1.  **Инициализация** параметров (например, нулями или случайными значениями).
>> 2.  **Вычисление предсказаний** по текущим параметрам: $(\hat{y}_i = \mathbf{w}^\top \mathbf{x}_i + b)$.
>> 3.  **Вычисление значения функции потерь** (MSE) на всей выборке.
>> 4.  **Корректировка параметров** с использованием методов оптимизации (например, **градиентный спуск**), чтобы уменьшить MSE.
>> 5.  Повторение шагов 2-4 до сходимости (достижения минимума ошибки или выполнения критерия остановки).
>
> ***Геометрическая интерпретация***
>> В пространстве параметров $((\mathbf{w}, b))$ мы ищем точку, в которой функция $(\text{MSE}(\mathbf{w}, b))$ принимает **минимальное значение**. Эта функция является выпуклой квадратичной формой, поэтому глобальный минимум существует и единственен (если признаки линейно независимы).

> [!question]- 3. Записать функционал Ridge-регрессии (L2-регуляризации) и объяснить, как L2-штраф влияет на значения коэффициентов и устойчивость модели.
> ***Функционал Ridge-регрессии***
>> $$ J_{\text{ridge}}(w, b) = \text{MSE}(w, b) + \lambda \|w\|_2^2 = \frac{1}{n} \sum_{i=1}^{n} (y_i - (w^\top x_i + b))^2 + \lambda \sum_{j=1}^{d} w_j^2 $$
>> где:
>> - $\text{MSE}(w, b)$ — среднеквадратичная ошибка
>> - $\lambda > 0$ — коэффициент регуляризации
>> - $\|w\|_2^2$ — L2-норма вектора весов (сумма квадратов)
>
> ***Влияние L2-штрафа***
>> 1. **"Сжатие" коэффициентов**: Все веса уменьшаются пропорционально, приближаясь к нулю, но **не обнуляются полностью**.
>> 2. **Снижение дисперсии**: Уменьшает переобучение, делая модель более устойчивой.
>> 3. **Борьба с мультиколлинеарностью**: При наличии сильно коррелирующих признаков, L2 делит вес между ними.
>> 4. **Контроль переобучения**: Чем больше $\lambda$, тем сильнее "сжимаются" веса → проще модель.
>
> ***Выбор $\lambda$***:
>> - **Слишком маленький $\lambda$**: слабая регуляризация → риск переобучения
>> - **Слишком большой $\lambda$**: сильная регуляризация → все веса около нуля → недообучение
>> - **Оптимальный $\lambda$**: подбирается по валидационной выборке

> [!question]- 4. Записать функционал Lasso-регрессии (L1-регуляризации) и объяснить, почему L1-штраф приводит к разреженности модели.
> ***Функционал Lasso-регрессии***
>> $$ J_{\text{lasso}}(w, b) = \text{MSE}(w, b) + \lambda \|w\|_1 = \frac{1}{n} \sum_{i=1}^{n} (y_i - (w^\top x_i + b))^2 + \lambda \sum_{j=1}^{d} |w_j| $$
>> где $\|w\|_1$ — L1-норма (сумма абсолютных значений весов).
>
> ***Разреженность (Sparsity) модели***
>> L1-штраф часто приводит к **точному обнулению** некоторых коэффициентов, создавая разреженную модель.
>>
>> ***Геометрическая интерпретация***:
>> ![Геометрическая интерпретация L1 и L2](https://i.imgur.com/MXWq02S.png)
>> - **L2 (Ridge)**: Ограничение в виде сферы → решение часто находится на гладкой поверхности.
>> - **L1 (Lasso)**: Ограничение в виде ромба (октаэдра) → решение часто попадает в **углы**, где некоторые координаты равны нулю.
>>
>> ***Практический смысл***: Lasso выполняет автоматический **отбор признаков** — неважные признаки получают нулевой вес.

> [!question]- 5. Сравнить Ridge и Lasso-регрессии.
> ***Сравнительная таблица***
>> | Критерий | **Ridge (L2)** | **Lasso (L1)** |
>> |----------|----------------|----------------|
>> | **Функционал** | $\text{MSE} + \lambda \sum w_j^2$ | $\text{MSE} + \lambda \sum |w_j|$ |
>> | **Влияние на веса** | Сжимает к нулю, но не обнуляет | Может обнулять некоторые веса |
>> | **Разреженность** | Нет | Да (автоматический отбор признаков) |
>> | **Мультиколлинеарность** | Делит вес между коррелирующими признаками | Выбирает один признак среди коррелирующих |
>> | **Интерпретируемость** | Средняя (все признаки остаются) | Высокая (остаются только важные признаки) |
>> | **Когда предпочтительнее** | Много слабых признаков, важна устойчивость | Мало важных признаков, нужен отбор признаков |
>
> ***Elastic Net***
>> Комбинирует L1 и L2 регуляризацию:
>> $$ J_{\text{elastic}}(w, b) = \text{MSE}(w, b) + \lambda_1 \|w\|_1 + \lambda_2 \|w\|_2^2 $$
>> - **Преимущества**: Сочетает отбор признаков (L1) и устойчивость к мультиколлинеарности (L2).
>> - **Применение**: Когда много признаков и среди них есть корреляции.

> [!question]- 6. Объяснить, зачем перед применением регуляризованных моделей стандартизуют признаки.
> ***Необходимость стандартизации***
>> Регуляризованные модели **чувствительны к масштабу признаков**, так как штраф применяется ко всем весам одинаково.
>>
>> ***Проблема без стандартизации***:
>> - Признак с большим размахом значений (например, зарплата: 50 000-200 000) будет иметь меньший вес.
>> - Признак с малым размахом (например, возраст: 18-65) будет иметь больший вес.
>> - L1/L2 штраф "несправедливо" наказывает веса, не учитывая масштаб признаков.
>
> ***Стандартизация решает***:
>> 1. **Справедливый штраф**: Все признаки приводятся к одинаковому масштабу.
>> 2. **Корректная регуляризация**: Штраф применяется равномерно ко всем признакам.
>> 3. **Ускорение сходимости**: Градиентный спуск работает эффективнее.
>
> ***Методы масштабирования***:
>> - **StandardScaler**: $(x - \text{mean}) / \text{std}$ → mean=0, std=1
>> - **MinMaxScaler**: $(x - \text{min}) / (\text{max} - \text{min})$ → диапазон [0, 1]
>
> ***Как подбирать параметр регуляризации $\lambda$***
>> 1. **Кросс-валидация**: Разбиение данных на k фолдов, обучение на k-1, тест на 1.
>> 2. **Кривые валидации**: Построение графика ошибки на обучении и валидации от $\lambda$.
>> 3. **GridSearch**: Поиск по сетке значений $\lambda$.
>> 4. **Выбор оптимального $\lambda$**: Точка, где ошибка на валидации минимальна.
>> 5. **Сравнение моделей**: Попробовать Ridge, Lasso, Elastic Net на валидации.
---
# Лекция 3. Логистическая регрессия

> [!question]- 1. Сформулировать задачу бинарной классификации в логистической регрессии. Что считается входом и выходом модели?
> ***Задача бинарной классификации***
>> Логистическая регрессия решает **задачу бинарной классификации**. Цель — по объекту, представленному вектором признаков, предсказать, к какому из двух классов (0 или 1, Negative или Positive) он принадлежит. Модель предсказывает не метку класса напрямую, а **вероятность** принадлежности объекта к целевому классу (обычно классу 1).
>
> ***Вход и выход модели***
>> **Вход модели**:
>> - Вектор признаков объекта $\mathbf{x} = [w_1, w_2, ..., w_n]^\top$ где  $\mathbf{x_j}$ — вещественнозначные или бинарные признаки.
>> - По сути, тот же вход, что и для линейной регрессии.
>>
>> **Выход модели**:
>> - **Вероятность** $(\hat{p}^{(i)} = P(y^{(i)} = 1$ | $\mathbf{x}^{(i)})$ \), то есть вероятность того, что объект $(i)$ принадлежит классу 1 при заданных его признаках.
>> - Для получения этой вероятности линейная комбинация признаков $( z = \mathbf{w}^\top \mathbf{x} + b )$ пропускается через **сигмоидную (логистическую) функцию** \(\sigma(z)\).
>
> ***Математическая формулировка***
>> 1.  **Линейный слой (логит)**: $( z^{(i)} = \mathbf{w}^\top \mathbf{x}^{(i)} + b )$
>> 2.  **Активация (сигмоида)**: $( \hat{p}^{(i)} = \sigma(z^{(i)}) = \frac{1}{1 + e^{-z^{(i)}}} )$
>>
>> **Расширенная форма** (с включением \(b\) в вектор весов):
>> $$ \hat{p}^{(i)} = \sigma(\tilde{\mathbf{w}}^\top \tilde{\mathbf{x}}^{(i)}) = \frac{1}{1 + e^{-\tilde{\mathbf{w}}^\top \tilde{\mathbf{x}}^{(i)}}} $$
>> где $(\tilde{\mathbf{x}}^{(i)} = [1, x_1^{(i)}, \dots, x_n^{(i)}]^\top\ , \tilde{\mathbf{w}} = [b, w_1, \dots, w_n]^\top)$
>
> ***Получение итогового класса***
>> Вероятность $(\hat{p}^{(i)})$ является основным выходом модели. Итоговая метка класса $(\hat{y}^{(i)})$ получается применением **порога** (по умолчанию 0.5):
>> $$ \hat{y}^{(i)} =
>> \begin{cases}
>> 1, & \text{если } \hat{p}^{(i)} \ge 0.5 \\
>> 0, & \text{если } \hat{p}^{(i)} < 0.5
>> \end{cases}
>> $$

> [!question]- 2. Записать выражение для вероятности наблюдения y ∈ {0,1} при фиксированном x.
> ***Вероятность для одного примера***
>> $$ p(y \mid x) = \sigma(z)^y \cdot (1 - \sigma(z))^{(1-y)} $$
>> где z = wᵀx + b

> [!question]- 3. Записать и объяснить выражение для вероятности наблюдения y ∈ {0,1} при фиксированном x.
> ***Вероятность в логистической регрессии***
>> В логистической регрессии используется **распределение Бернулли** с параметром $p = \sigma(z)$, где:
>> - $\sigma(z) = \frac{1}{1 + e^{-z}}$ — сигмоидная функция
>> - $z = w^\top x + b$ — линейный отклик
>>
>> **Вероятность для одного объекта**:
>> $$ p(y \mid x) = \sigma(z)^y \cdot (1 - \sigma(z))^{(1-y)}, \quad y \in \{0, 1\} $$
>>
>> ***Объяснение формулы***:
>> - Если $y = 1$: $p(1 \mid x) = \sigma(z)^1 \cdot (1 - \sigma(z))^0 = \sigma(z)$
>> - Если $y = 0$: $p(0 \mid x) = \sigma(z)^0 \cdot (1 - \sigma(z))^1 = 1 - \sigma(z)$
>>
>> Таким образом, формула компактно описывает вероятность для обоих классов.
>
> ***Правдоподобие всей выборки***
>> При предположении независимости объектов:
>> $$ \mathcal{L}(w, b) = \prod_{i=1}^n \sigma(z_i)^{y_i} \cdot (1 - \sigma(z_i))^{(1-y_i)} $$
>> где $z_i = w^\top x_i + b$.
>> Это произведение вероятностей по всем объектам выборки.

> [!question]- 4. Вывести функцию потерь логистической регрессии (log loss).
> ***Вывод log loss из правдоподобия***
>> 1. **Логарифмирование правдоподобия** (удобнее работать с суммой):
>> $$ \log \mathcal{L}(w, b) = \sum_{i=1}^n \left[ y_i \log \sigma(z_i) + (1-y_i) \log (1 - \sigma(z_i)) \right] $$
>>
>> 2. **Преобразование к функции потерь**:
>> - Меняем знак (максимизация правдоподобия → минимизация потерь)
>> - Добавляем усреднение по выборке:
>> $$ J(w, b) = -\frac{1}{n} \sum_{i=1}^n \left[ y_i \log \sigma(z_i) + (1-y_i) \log (1 - \sigma(z_i)) \right] $$
>>
>> Это и есть **log loss** (бинарная кросс-энтропия).
>
> ***Свойства log loss***
>> - **Выпуклая функция**: гарантирует единственный глобальный минимум.
>> - **Штрафует за уверенные ошибки**: если модель уверенно предсказывает неверный класс, штраф велик.
>> - **Дифференцируема**: можно использовать градиентные методы оптимизации.

> [!question]- 5. Пояснить, как и зачем добавляются L1- и L2-регуляризации в логистическую регрессию.
> ***Регуляризация в логистической регрессии***
>> Аналогично линейной регрессии, в логистическую регрессию добавляются штрафы на веса для борьбы с переобучением.
>
> ***Регуляризованные функционалы***
>> **L2-регуляризация (Ridge)**:
>> $$ J_{\text{ridge}}(w, b) = J(w, b) + \lambda \|w\|_2^2 $$
>>
>> **L1-регуляризация (Lasso)**:
>> $$ J_{\text{lasso}}(w, b) = J(w, b) + \lambda \|w\|_1 $$
>>
>> где $J(w, b)$ — исходный log loss, $\lambda > 0$ — коэффициент регуляризации.
>
> ***Влияние регуляризации***
>> | Аспект | **L2 (Ridge)** | **L1 (Lasso)** |
>> |--------|----------------|----------------|
>> | **Переобучение** | Уменьшает, "сжимая" все веса | Уменьшает, обнуляя неважные веса |
>> | **Интерпретируемость** | Все признаки остаются, сложнее интерпретировать | Автоматический отбор признаков, проще интерпретировать |
>> | **Устойчивость** | Устойчивость к мультиколлинеарности | Выбирает один признак из коррелирующих |
>> | **Разреженность** | Нет (веса маленькие, но не нулевые) | Да (многие веса точно равны 0) |
>
> ***Выбор типа регуляризации***
>> - **L2 (Ridge)**: когда важны все признаки, но нужно контролировать их влияние.
>> - **L1 (Lasso)**: когда нужно выбрать наиболее важные признаки для интерпретации.
>> - **Elastic Net**: комбинация L1 и L2 для баланса между отбором признаков и устойчивостью.
---
# Лекция 4. Случайные деревья и ансамбли

> [!question]- 1. Описать структуру решающего дерева: что такое внутренний узел, лист, ребро, глубина дерева. Чем дерево классификации отличается от дерева регрессии по типу предсказания в листе?
> ***Структура решающего дерева***
>> Решающее дерево — древовидная структура, состоящая из узлов и ребер. Основные элементы:
>>
>> 1.  **Внутренний узел (decision node)**:
>>     - Узел, который проверяет значение определенного признака объекта.
>>     - Содержит **условие (пороговое значение)** вида $( x_j <= t )$ (для непрерывных признаков) или $( x_j = value_k )$ (для категориальных).
>>     - Имеет **два или более потомков** (обычно 2 для бинарного дерева).
>>
>> 2.  **Лист (leaf node, terminal node)**:
>>     - Конечный узел, не имеющий потомков.
>>     - Содержит **итоговое предсказание** модели для объектов, попавших в этот лист.
>>     - Количество объектов в листе может быть разным.
>>
>> 3.  **Ребро (edge, branch)**:
>>     - Связь между родительским и дочерним узлом.
>>     - Соответствует **результату проверки условия** в родительском узле (например, «Да» → левое поддерево, «Нет» → правое).
>>
>> 4.  **Глубина дерева (depth)**:
>>     - **Максимальная длина пути** от корневого узла до любого листа (количество пройденных ребер).
>>     - **Глубина конкретного узла**: длина пути от корня до этого узла.
>>
>> **Графическое представление**:
>> ```
>>                         [Корень: x1 ≤ 0.5?]        ← внутренний узел
>>                         /                  \
>>                  [x2 ≤ 1.0?]           [Лист: класс A]  ← лист
>>                 /            \
>>        [Лист: класс B]  [Лист: класс C]
>> ```
>> Глубина этого дерева = 2.
>
> ***Различие деревьев классификации и регрессии по предсказанию в листе***
>>
>> | Аспект | **Дерево классификации** | **Дерево регрессии** |
>> | :--- | :--- | :--- |
>> | **Тип целевой переменной** | Категориальная (класс) | Непрерывная (числовая) |
>> | **Предсказание в листе** | **Метка класса** или **вероятности классов** | **Числовое значение** (среднее) |
>> | **Математическая форма** | $$ \hat{y}_{\text{leaf}} = \arg\max_{k} \, p_k $$ <br> где \(p_k\) — доля класса \(k\) в листе | $$ \hat{y}_{\text{leaf}} = \frac{1}{N_{\text{leaf}}} \sum_{i \in \text{leaf}} y_i $$ <br> (среднее целевых значений объектов листа) |
>> | **Пример** | Лист содержит 10 объектов: 7 класса "Спам", 3 класса "Не спам". <br> **Предсказание:** "Спам" (вероятность 0.7). | Лист содержит 5 объектов со значениями: {10.2, 11.1, 9.8, 10.5, 10.4}. <br> **Предсказание:** \( (10.2+11.1+9.8+10.5+10.4)/5 = 10.4 \). |
>> | **Критерий оптимизации при построении** | Энтропия, индекс Джини, неопределенность | Дисперсия, MSE (минимизация квадратов отклонений) |
>
> ***Ключевое отличие***
>> **Дерево классификации** возвращает **дискретную метку** (или распределение вероятностей) — ответ на вопрос *«Какой класс?»*.  
>> **Дерево регрессии** возвращает **непрерывное число** — ответ на вопрос *«Какое значение?»*.  
>> Структура (узлы, ребра, глубина) строится аналогично, но **содержание листов** и **критерии ветвления** различны.
# Лекция 5. Бустинг и градиентный бустинг над деревьями
>[!question]- 1. Сформулировать общую идею бустинга. Чем бустинг принципиально отличается от бэггинга и стэкинга?
>
> **Общая идея**
> 
> Последовательное добавление слабых моделей, каждая из которых исправляет ошибки предыдущей, i.e. предсказывает ошибку предыдущей.
>
> ***Отличие от бэггинга и стэкинга***
>   
> При бэггинге обучется несколько моделей, и финальное предсказание формируется "голосованием" (берется мода или среднее от всех предсказаний)
> При стэкинге на предсказаниях нескольких моделей обучается еще одна модель, которая сможет лучше комбинировать их ответы, чем просто мода или среднее.
> При бустинге же модели работают как бы не параллельно, а последовательно. Каждая последующая модель, кроме первой, старается предсказать не таргет переменную, как в бэггинге или стэкинге, а ошибку предыдущей модели.
> Бэггинг и стэкинг менее чувствительны к отдельным выбросам. Бустинг чувствителен к шуму (важна регуляризация).

>[!question]- 2. Записать и_ли объяснить объяснить общее обновление модели в градиентном бустинге [1]
> $$ F_{M}(x) = F_{M-1}(x) + v*h_{m}(x) $$
> 
> Где 
> - $F_{0}(x)$ - изначальная модель, которая грубо предсказывает ошибку
> - $h_{M}(x)$ - модель, которая предсказывает ошибки $F_{M-1}(x)  
> - $v \in (0; 1]$ - скорость обучения (i.e. как сильно модель каждой итерации влияет на конечную модель. Чем меньше  скорость обучения, тем больше нужно обучить моделей, но тем более точно можно скорректировать финальную модель)
> 
> Оно же:
> 
> $$ F(x) = F_{0}(x) + \sum_{i=1}^{h} h_{i}(x) * v^i $$

>[!question]- 3. Пояснить точку зрения градиентного спуска в пространстве функций: как задается функционал ошибки L(F) и какую роль играют псевдо-остатки (антиградиенты) на обучающих объектах.
>
> **Пространство функций**
>
> Пространство функций - это множество слабых функций h, которые мы перебираем для нахождения лучшей финальной функции F
>
> **Как задается функционал ошибка L(F)**
> 
> $$ L(F) = \sum_{i=1}^{n}l(y_{i}, F(x_{i})) $$
> 
> Где F - искомая функция, а l - выбранная функция потерь.
> 
>  **Псевдо-остатки**
>  
>  На каждом шаге нам нужна модель h, которая будет предсказывать ошибку прошлой модели F. 
> 
>  $$ g_{im} = \frac{\partial l(y_{i}, F_{m-1}(x_{i}))}{\partial F_{m-1}(x_{i})} $$
>  
>  $$ h_{m} \approx -g_{im} $$
>  
>  I.e. псевдо-остатки (производная Фреше в обобщенном метрическом пространстве) пропорциональны предсказаниям модели h.
>  
>  Градиентный бустинг называется так, т.к. формула сильно похожа на формулу градиентного спуска
>  
>  $$ x = x_{0} - \sum_{i=1}^{n} v_{i} g_{'}(x_{i}) $$

> [!question]- 4. Записать и_ли объяснить шаг алгоритма градиентного бустинга над деревьями: вычисление псевдо-остатков, обучение регрессионного дерева по этим значениям, поиск оптимальных сдвигов по листам и обновление ансамбля [1]
> 
> 1. Вычисление псевдо-остатков $$ r_{im} = \frac{\partial l(y_{i}, F_{m-1}(x_{i}))}{\partial F_{m-1}(x_{i})} $$
> 2. Обучение регрессионного дерева $h_{m}(x)$ по парам ($x_{i}$, $r_{im}$)
> 3. Нахождение оптимального сдвига (константы) по листам: для каждого листа $R_{jm}$ $$ γ_{jm} = arg\min_{γ} \sum_{x_{i} \in R_{jm}} l(y_{i}, F_{m-1}(x_{i}) + γ) $$
> 4. Обновление модели $$ F_{m}(x) = F_{m-1}(x) + v * \sum_{j} γ_{jm} 1\{x \in R_{jm} \} $$

>[!question]- 5. Перечислить основные способы регуляризации в градиентном бустинге: малая скорость обучения v, ограничение глубины деревьев, минимальный размер листа, субсемплинг объектов, субсемплинг признаков, ранняя остановка по валидационной выборке.
>
> 1. Скорость обучения (shrinkage)  $v \in (0; 1]$. Чем меньше, тем устойчивее, но нужно больше деревьев.
> 2. Глубина дерева / число листьев: неглубокие деревья (3-8 уровней) приводят к слабым базовым моделям.
> 3. Субсемплинг объектов: обучение $h_{m}$ на случайной доле данных (обычно от 0.5 до 0.9)
> 4. Субсемплинг признаков: случайный поднабор признаков на сплите/уровне/дереве.
> 5. Минимальный размер листа, L2-штраф на веса листок, макс. число узлов.
> 6. Ранняя остановка по валидации: мониторинг метрики и прекращение роста M (перетекает в некст вопрос)

>[!question]- 6. Объяснить, как по поведению метрик на обучающей и валидационной выборках диагностировать переобучение бустинговой модели и как выбирать оптимальное число итераций.
>
> **Переобучение**
> 
> При подборе гиперпараметров нужно стремиться к уменьшению метрики на валидации и сохранению метрики на обучающей выборке. Если материка на обучающей выборке уменьшается, а на валидационной - нет, то это признак переобучения.
> 
> **Число итераций**
> 
> Подбирается так же, как и любой гиперпараметр, - по метрике валидационной выборке
---
# Лекция 6. Кластеризация, SVD и PCA

> [!question]- 1. Дать определение обучению без учителя. Какие задачи обычно относят к обучению без учителя? Приведите примеры.
> ***Определение обучения без учителя***
>> **Обучение без учителя** — это метод машинного обучения, при котором алгоритм работает с **неразмеченными данными** (отсутствует целевая переменная y) с целью обнаружения скрытых структур, закономерностей и взаимосвязей в данных.
>
> ***Основные задачи обучения без учителя***
>> **Кластеризация**: Разбиение данных на группы (кластеры) схожих объектов.
>> *Примеры*: геологическое обнаружение минералов, кластеризация генов, сегментация клиентов.
>>
>> **Снижение размерности**: Уменьшение количества признаков при сохранении максимальной информации.
>> *Примеры*: визуализация многомерных данных, ускорение обучения моделей.
>>
>> **Выявление латентных признаков**: Обнаружение скрытых факторов или тем в данных.
>> *Пример*: анализ скрытых интересов пользователей в рекомендательных системах.

> [!question]- 2. Описать алгоритм K-Means. Записать и объяснить целевую функцию, которую алгоритм минимизирует.
> ***Алгоритм K-Means***
>> 1. **Инициализация**: Выбор K случайных точек в качестве начальных центроидов.
>> 2. **Присваивание**: Каждый объект относится к кластеру с ближайшим центроидом.
>> 3. **Обновление**: Для каждого кластера вычисляется новый центроид как среднее всех объектов в кластере.
>> 4. **Повторение**: Шаги 2-3 повторяются до сходимости (центроиды перестают значительно меняться).
>
> ***Целевая функция (Within-Cluster Sum of Squares)***
>> $$ J(C, \mu) = \sum_{k=1}^{K} \sum_{x_i \in C_k} \| x_i - \mu_k \|^2 $$
>> где:
>> - $K$ — количество кластеров
>> - $C_k$ — множество объектов в кластере k
>> - $\mu_k$ — центроид кластера k
>> - $\| x_i - \mu_k \|$ — евклидово расстояние между объектом и центроидом
>>
>> Алгоритм минимизирует сумму квадратов расстояний от каждого объекта до центроида его кластера.

> [!question]- 3. Перечислить основные преимущества и недостатки K-Means.
> ***Преимущества K-Means***
>> 1. **Быстродействие**: Линейная сложность $O(n \cdot k \cdot d \cdot t)$, где n — число объектов, k — число кластеров, d — размерность, t — число итераций.
>> 2. **Масштабируемость**: Эффективно работает с большими наборами данных.
>> 3. **Интерпретируемость**: Результат — наглядные центры кластеров и принадлежность объектов.
>
> ***Недостатки K-Means***
>> 4. **Чувствительность к масштабу**: Признаки с большим разбросом доминируют в расстоянии. Необходима стандартизация.
>> 5. **Чувствительность к выбросам**: Выбросы сильно смещают центроиды из-за квадратичной функции потерь.
>> 6. **Предположение о сферичности**: Предполагает, что кластеры имеют сферическую форму и одинаковый размер.
>> 7. **Необходимость задания K**: Требует заранее задавать число кластеров.

> [!question]- 4. Объяснить алгоритм DBSCAN.
> ***Основная идея DBSCAN***
>> DBSCAN (Density-Based Spatial Clustering of Applications with Noise) находит области **высокой плотности**, разделенные областями **низкой плотности**.
>
> ***Параметры алгоритма***
>> **ε (epsilon)** — радиус окрестности для поиска соседей.
>> **min_samples** — минимальное количество точек для образования плотной области (ядра).
>
> ***Типы точек***
>> **Ядровая точка**: Имеет не менее min_samples точек в ε-окрестности (включая саму себя).
>> **Пограничная точка**: Находится в ε-окрестности ядровой точки, но сама не является ядровой.
>> **Шумовая точка**: Не является ни ядровой, ни пограничной.
>
> ***Алгоритм***
>> 8. Выбираем произвольную непосещенную точку.
>> 9. Если она ядровая — создаем новый кластер и добавляем все достижимые из нее точки (в пределах ε).
>> 10. Если нет — помечаем как шум.
>> 11. Повторяем для всех непосещенных точек.

> [!question]- 5. Сравнить DBSCAN и K-Means.
> ***Сравнительная таблица***
>> | Критерий | **K-Means** | **DBSCAN** |
>> |----------|-------------|------------|
>> | **Форма кластеров** | Сферическая | Произвольная |
>> | **Устойчивость к выбросам** | Низкая | Высокая (помечает выбросы как шум) |
>> | **Необходимость задания числа кластеров** | Требует K | Определяет автоматически |
>> | **Чувствительность к плотности данных** | Игнорирует плотность, делит пространство равномерно | Основан на плотности, находит кластеры разной плотности |
>> | **Работа с шумом** | Присваивает шумовые точки ближайшим кластерам | Выделяет шумовые точки отдельно |

> [!question]- 6. Описать идею агломеративной иерархической кластеризации.
> ***Основная идея***
>> **Агломеративная кластеризация** начинается с того, что каждый объект считается отдельным кластером, затем последовательно объединяет **ближайшие** кластеры, пока не останется один кластер или не будет достигнут критерий остановки.
>
> ***Правила слияния (меры связи)***
>> **Single Linkage** (одиночная связь): Расстояние между ближайшими точками двух кластеров.
>> **Complete Linkage** (полная связь): Расстояние между самыми далекими точками.
>> **Average Linkage** (средняя связь): Среднее расстояние между всеми парами точек из двух кластеров.
>> **Ward's Method**: Минимизирует увеличение общей внутрикластерной дисперсии при слиянии.
>
> ***Дендрограмма***
>> **Дендрограмма** — древовидная диаграмма, показывающая последовательность слияний кластеров и расстояния, на которых они происходят. Горизонтальный разрез дендрограммы определяет количество итоговых кластеров.

> [!question]- 7. Перечислить достоинства и недостатки иерархической кластеризации.
> ***Достоинства***
>> 12. **Наглядность**: Дендрограмма позволяет визуально оценить структуру данных.
>> 13. **Не требует задания числа кластеров**: Можно выбрать уровень среза после построения.
>> 14. **Детерминированность**: Результат не зависит от случайной инициализации (в отличие от K-Means).
>
> ***Недостатки***
>> 15. **Высокая вычислительная сложность**: $O(n^3)$ для большинства реализаций, $O(n^2)$ для оптимизированных.
>> 16. **Чувствительность к шуму и выбросам**: Могут создаваться нерелевантные кластеры на ранних этапах.
>> 17. **Необратимость решений**: После слияния кластеров процесс нельзя "откатить".
>> 18. **Плохая масштабируемость**: На больших выборках (более $10^4$ объектов) становится непрактичным.

> [!question]- 8. Сформулировать основные цели снижения размерности.
> ***Цели снижения размерности***
>> 19. **Борьба с проклятием размерности**: Уменьшение числа признаков для более эффективного обучения моделей.
>> 20. **Устранение мультиколлинеарности**: Удаление коррелирующих признаков.
>> 21. **Визуализация данных**: Представление многомерных данных в 2D или 3D.
>> 22. **Сжатие данных**: Уменьшение объема хранимой информации.
>> 23. **Ускорение вычислений**: Меньше признаков — быстрее работа алгоритмов.
>> 24. **Улучшение интерпретируемости**: Выделение наиболее значимых признаков.
>> 25. **Подавление шума**: Отсечение незначимых компонент.
>
> ***Популярные алгоритмы***
>> **PCA (Principal Component Analysis)** — линейный метод, находит ортогональные направления максимальной дисперсии.
>> **SVD (Singular Value Decomposition)** — матричная факторизация, лежит в основе PCA.
>> **t-SNE (t-distributed Stochastic Neighbor Embedding)** — нелинейный метод для визуализации.
>> **UMAP (Uniform Manifold Approximation and Projection)** — современный нелинейный метод.